{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"e049848afe1440c78f8e93a2c3dd4b6b","colab_type":"text","deepnote_cell_type":"markdown","id":"EgiF12Hf1Dhs"},"source":["# Pose Estimation (Camera)\n","This notebook presents the demonstration of pose estimation with ICP of a book for the LibreBot by T2325 for CS 492 COURSE."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.1)\n","Collecting opencv-python\n","  Downloading opencv_python-4.7.0.72-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (61.8 MB)\n","\u001b[K     |████████████████████████████████| 61.8 MB 10.6 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.3; python_version >= \"3.8\" in /usr/local/lib/python3.8/dist-packages (from opencv-python) (1.21.1)\n","Installing collected packages: opencv-python\n","Successfully installed opencv-python-4.7.0.72\n","Requirement already satisfied: matplotlib in /usr/lib/python3/dist-packages (3.1.2)\n","Collecting transformers\n","  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n","\u001b[K     |████████████████████████████████| 7.1 MB 1.3 MB/s eta 0:00:01\n","\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[K     |████████████████████████████████| 7.8 MB 11.2 MB/s eta 0:00:01\n","\u001b[?25hCollecting huggingface-hub<1.0,>=0.14.1\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[K     |████████████████████████████████| 224 kB 12.2 MB/s eta 0:00:01\n","\u001b[?25hCollecting tqdm>=4.27\n","  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n","\u001b[K     |████████████████████████████████| 77 kB 9.3 MB/s  eta 0:00:01\n","\u001b[?25hCollecting regex!=2019.12.17\n","  Downloading regex-2023.5.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (771 kB)\n","\u001b[K     |████████████████████████████████| 771 kB 11.5 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.1)\n","Collecting packaging>=20.0\n","  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n","\u001b[K     |████████████████████████████████| 48 kB 8.8 MB/s  eta 0:00:01\n","\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.3.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.26.0)\n","Collecting filelock\n","  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (3.10.0.2)\n","Collecting fsspec\n","  Downloading fsspec-2023.5.0-py3-none-any.whl (160 kB)\n","\u001b[K     |████████████████████████████████| 160 kB 11.2 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.0.7)\n","Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (3.3)\n","Installing collected packages: tokenizers, tqdm, fsspec, packaging, filelock, huggingface-hub, regex, transformers\n","Successfully installed filelock-3.12.0 fsspec-2023.5.0 huggingface-hub-0.14.1 packaging-23.1 regex-2023.5.5 tokenizers-0.13.3 tqdm-4.65.0 transformers-4.29.1\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (2.26.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests) (1.26.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests) (2021.10.8)\n","Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests) (2.0.7)\n","Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests) (3.3)\n","Collecting torchvision\n","  Downloading torchvision-0.15.2-cp38-cp38-manylinux1_x86_64.whl (33.8 MB)\n","\u001b[K     |████████████████████████████████| 33.8 MB 582 kB/s  eta 0:00:01\n","\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/lib/python3/dist-packages (from torchvision) (7.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.26.0)\n","Collecting torch==2.0.1\n","  Downloading torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n","\u001b[K     |████████████████████████████████| 619.9 MB 31 kB/s s eta 0:00:01     |███████                         | 137.6 MB 12.2 MB/s eta 0:00:40     |███████▎                        | 139.9 MB 12.2 MB/s eta 0:00:40     |████████████████████▍           | 394.4 MB 12.8 MB/s eta 0:00:18ta 0:00:04\n","\u001b[?25hRequirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2021.10.8)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.26.7)\n","Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (3.3)\n","Collecting nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n","\u001b[K     |████████████████████████████████| 173.2 MB 68 kB/s s eta 0:00:01\n","\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n","\u001b[K     |████████████████████████████████| 168.4 MB 11.8 MB/s eta 0:00:01\n","\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n","\u001b[K     |████████████████████████████████| 102.6 MB 11 kB/s s eta 0:00:01 12.0 MB/s eta 0:00:03\n","\u001b[?25hCollecting networkx\n","  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n","\u001b[K     |████████████████████████████████| 2.1 MB 13.1 MB/s eta 0:00:01\n","\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n","\u001b[K     |████████████████████████████████| 177.1 MB 11.1 MB/s eta 0:00:01     |█████████████████████▌          | 119.1 MB 10.5 MB/s eta 0:00:06     |██████████████████████████████▍ | 168.4 MB 10.5 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (3.10.0.2)\n","Collecting triton==2.0.0; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n","\u001b[K     |████████████████████████████████| 63.2 MB 12.1 MB/s eta 0:00:01\n","\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n","\u001b[K     |████████████████████████████████| 54.6 MB 10.6 MB/s eta 0:00:01     |████████                        | 13.8 MB 10.8 MB/s eta 0:00:04     |████████████                    | 20.4 MB 10.8 MB/s eta 0:00:04\n","\u001b[?25hCollecting sympy\n","  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n","\u001b[K     |████████████████████████████████| 5.7 MB 11.3 MB/s eta 0:00:01\n","\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n","\u001b[K     |████████████████████████████████| 98 kB 10.0 MB/s eta 0:00:01\n","\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n","\u001b[K     |████████████████████████████████| 557.1 MB 22 kB/s s eta 0:00:01MB 10.5 MB/s eta 0:00:42MB 10.6 MB/s eta 0:00:39��█▌            | 339.6 MB 10.9 MB/s eta 0:00:21| 440.0 MB 10.6 MB/s eta 0:00:12��██████████████▋ | 533.7 MB 11.8 MB/s eta 0:00:02�█▊ | 535.1 MB 11.8 MB/s eta 0:00:02\n","\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (3.0.1)\n","Collecting nvidia-cuda-nvrtc-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n","\u001b[K     |████████████████████████████████| 21.0 MB 11.7 MB/s eta 0:00:0186 kB 6.2 MB/s eta 0:00:04\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from torch==2.0.1->torchvision) (3.12.0)\n","Collecting nvidia-cuda-runtime-cu11==11.7.99; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n","\u001b[K     |████████████████████████████████| 849 kB 11.2 MB/s eta 0:00:01     |███████████████                 | 399 kB 11.2 MB/s eta 0:00:01\n","\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n","\u001b[K     |████████████████████████████████| 317.1 MB 64 kB/s  eta 0:00:011    |█████▎                          | 52.2 MB 10.6 MB/s eta 0:00:26MB/s eta 0:00:18     |████████████████▎               | 161.3 MB 11.6 MB/s eta 0:00:14███████▍              | 172.2 MB 12.1 MB/s eta 0:00:12172.6 MB 12.1 MB/s eta 0:00:12████████████▎         | 220.3 MB 12.2 MB/s eta 0:00:08     |███████████████████████████▌    | 272.8 MB 10.5 MB/s eta 0:00:0501��███████████▌| 312.0 MB 10.6 MB/s eta 0:00:01\n","\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101; platform_system == \"Linux\" and platform_machine == \"x86_64\"\n","  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n","\u001b[K     |████████████████████████████████| 11.8 MB 6.9 MB/s eta 0:00:01      | 2.5 MB 8.2 MB/s eta 0:00:02B 8.2 MB/s eta 0:00:01 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.1->torchvision) (45.2.0)\n","Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cusparse-cu11==11.7.4.91; platform_system == \"Linux\" and platform_machine == \"x86_64\"->torch==2.0.1->torchvision) (0.34.2)\n","Collecting lit\n","  Downloading lit-16.0.3.tar.gz (138 kB)\n","\u001b[K     |████████████████████████████████| 138 kB 9.8 MB/s eta 0:00:01\n","\u001b[?25hCollecting cmake\n","  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n","\u001b[K     |████████████████████████████████| 24.0 MB 998 kB/s eta 0:00:01\n","\u001b[?25hCollecting mpmath>=0.19\n","  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n","\u001b[K     |████████████████████████████████| 536 kB 13.5 MB/s eta 0:00:01     | 419 kB 13.5 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.8/dist-packages (from jinja2->torch==2.0.1->torchvision) (2.0.1)\n","Building wheels for collected packages: lit\n","  Building wheel for lit (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for lit: filename=lit-16.0.3-py3-none-any.whl size=88191 sha256=569c656c027d094e0b384f96d5865546896c511c2668dc4811cdb66c534dd1f5\n","  Stored in directory: /root/.cache/pip/wheels/01/20/c2/b32a74e477abe541734225f8d5ed8b9e284d1f8580f6828445\n","Successfully built lit\n","Installing collected packages: nvidia-cusparse-cu11, nvidia-cufft-cu11, nvidia-cublas-cu11, nvidia-cusolver-cu11, networkx, nvidia-nccl-cu11, lit, cmake, triton, nvidia-curand-cu11, mpmath, sympy, nvidia-nvtx-cu11, nvidia-cudnn-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, torch, torchvision\n","  Attempting uninstall: torch\n","    Found existing installation: torch 1.12.1\n","    Uninstalling torch-1.12.1:\n","      Successfully uninstalled torch-1.12.1\n","Successfully installed cmake-3.26.3 lit-16.0.3 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.12 torch-2.0.1 torchvision-0.15.2 triton-2.0.0\n","Requirement already satisfied: Pillow in /usr/lib/python3/dist-packages (7.0.0)\n","Collecting git+https://github.com/facebookresearch/segment-anything.git\n","  Cloning https://github.com/facebookresearch/segment-anything.git to /tmp/pip-req-build-7igjd5zr\n","  Running command git clone -q https://github.com/facebookresearch/segment-anything.git /tmp/pip-req-build-7igjd5zr\n","Building wheels for collected packages: segment-anything\n","  Building wheel for segment-anything (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for segment-anything: filename=segment_anything-1.0-py3-none-any.whl size=36610 sha256=5400b61282ffe233c773655a69ffc465b3002208901da0ce70292ea32c21e505\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-f5gv5fok/wheels/b0/7e/40/20f0b1e23280cc4a66dc8009c29f42cb4afc1b205bc5814786\n","Successfully built segment-anything\n","Installing collected packages: segment-anything\n","Successfully installed segment-anything-1.0\n"]}],"source":["\n","!pip install numpy\n","!pip install opencv-python\n","!pip install matplotlib\n","!pip install transformers\n","!pip install requests\n","!pip install torchvision\n","!pip install Pillow\n","!pip install git+https://github.com/facebookresearch/segment-anything.git\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["\n","import torch\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import cv2\n","\n","def show_anns(anns):\n","    if len(anns) == 0:\n","        return\n","    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n","    ax = plt.gca()\n","    ax.set_autoscale_on(False)\n","    polygons = []\n","    color = []\n","    for ann in sorted_anns:\n","        m = ann['segmentation']\n","        img = np.ones((m.shape[0], m.shape[1], 3))\n","        color_mask = np.random.random((1, 3)).tolist()[0]\n","        for i in range(3):\n","            img[:,:,i] = color_mask[i]\n","        ax.imshow(np.dstack((img, m*0.35)))\n","\n","import sys\n","sys.path.append(\"..\")\n","from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n","\n","\n","\n","sam_checkpoint = \"sam_vit_h_4b8939.pth\"\n","model_type = \"vit_h\"\n","\n","#device = \"cuda\"\n","device = torch.device(\"cpu\")\n","\n","\n","sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n","sam.to(device=device)\n","\n","mask_generator = SamAutomaticMaskGenerator(sam)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Drake code starts"]},{"cell_type":"code","execution_count":3,"metadata":{"cell_id":"55b198d40733432283fe8716b6929e6c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":822,"execution_start":1682523013410,"is_code_hidden":false,"source_hash":"9e43a7ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-11 22:03:31.206027 \n"]}],"source":["import numpy as np\n","from pydrake.all import (\n","    AbstractValue,\n","    AngleAxis,\n","    Concatenate,\n","    DiagramBuilder,\n","    LeafSystem,\n","    MeshcatVisualizer,\n","    PiecewisePolynomial,\n","    PiecewisePose,\n","    PointCloud,\n","    RigidTransform,\n","    RollPitchYaw,\n","    Simulator,\n","    StartMeshcat,\n",")\n","\n","from manipulation import running_as_notebook\n","from manipulation.icp import IterativeClosestPoint\n","from manipulation.meshcat_utils import AddMeshcatTriad\n","from manipulation.mustard_depth_camera_example import MustardPointCloud\n","from manipulation.pick import (\n","    MakeGripperCommandTrajectory,\n","    MakeGripperFrames,\n","    MakeGripperPoseTrajectory,\n",")\n","from manipulation.scenarios import *\n","from manipulation.scenarios import AddIiwaDifferentialIK, MakeManipulationStation\n","\n","import matplotlib.pyplot as plt\n","import mpld3\n","import numpy as np\n","import pydot\n","import CrackerBoxPointCloud\n","from IPython.display import SVG, clear_output, display\n","from pydrake.all import (\n","    AbstractValue,\n","    AddMultibodyPlantSceneGraph,\n","    AngleAxis,\n","    DiagramBuilder,\n","    FindResourceOrThrow,\n","    Integrator,\n","    JacobianWrtVariable,\n","    LeafSystem,\n","    MathematicalProgram,\n","    MeshcatVisualizer,\n","    SnoptSolver,\n","    Solve,\n","    eq,\n","    ge,\n","    le,\n","    MultibodyPlant,\n","    MultibodyPositionToGeometryPose,\n","    Parser,\n","    PiecewisePolynomial,\n","    PiecewisePose,\n","    Quaternion,\n","    Rgba,\n","    RigidTransform,\n","    RotationMatrix,\n","    SceneGraph,\n","    Simulator,\n","    StartMeshcat,\n","    TrajectorySource,\n",")\n","from pydrake.all import (\n","    AbstractValue,\n","    AngleAxis,\n","    Concatenate,\n","    DiagramBuilder,\n","    LeafSystem,\n","    MeshcatVisualizer,\n","    PiecewisePolynomial,\n","    PiecewisePose,\n","    PointCloud,\n","    RigidTransform,\n","    RollPitchYaw,\n","    Simulator,\n","    StartMeshcat,\n",")\n","\n","from manipulation import running_as_notebook, FindResource\n","from manipulation.scenarios import (\n","    AddIiwaDifferentialIK,\n","    MakeManipulationStation,\n","    AddMultibodyTriad,\n","    AddShape,\n",")\n","\n","from manipulation.meshcat_utils import AddMeshcatTriad\n","from pydrake.manipulation.planner import (\n","    DifferentialInverseKinematicsIntegrator,\n","    DifferentialInverseKinematicsParameters,\n","    DifferentialInverseKinematicsStatus,\n",")\n","from pydrake.manipulation.planner import DoDifferentialInverseKinematics\n","from manipulation.icp import IterativeClosestPoint\n","from pydrake.all import (\n","    Box,\n","    Sphere,\n","    PrismaticJoint,\n","    RevoluteJoint,\n","    SpatialInertia,\n","    UnitInertia,\n","    BaseField,\n","    Fields,\n",")  # PlanarJoint\n","from datetime import datetime\n","\n","if running_as_notebook:\n","    mpld3.enable_notebook()\n","\n","from PIL import Image\n","\n","\n","def saat(msg=\"\"):\n","    print(str(datetime.now()), msg)\n","\n","\n","saat()"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-11 22:03:31.275698 \n"]}],"source":["import numpy as np\n","from pydrake.all import (AbstractValue, AngleAxis, Concatenate, DiagramBuilder,\n","                         LeafSystem, MeshcatVisualizer, PiecewisePolynomial,\n","                         PiecewisePose, PointCloud, RigidTransform,\n","                         RollPitchYaw, Simulator, StartMeshcat)\n","\n","from manipulation import running_as_notebook\n","from manipulation.icp import IterativeClosestPoint\n","from manipulation.meshcat_utils import AddMeshcatTriad\n","from manipulation.mustard_depth_camera_example import MustardPointCloud\n","from manipulation.pick import (MakeGripperCommandTrajectory, MakeGripperFrames,\n","                               MakeGripperPoseTrajectory)\n","from manipulation.scenarios import *\n","from manipulation.scenarios import (AddIiwaDifferentialIK,\n","                                    MakeManipulationStation)\n","                                    \n","import matplotlib.pyplot as plt\n","import mpld3\n","import numpy as np\n","import pydot\n","import CrackerBoxPointCloud\n","from IPython.display import SVG, clear_output, display\n","from pydrake.all import (AbstractValue, AddMultibodyPlantSceneGraph, AngleAxis,\n","                         DiagramBuilder, FindResourceOrThrow, Integrator,\n","                         JacobianWrtVariable, LeafSystem, MathematicalProgram,\n","                         MeshcatVisualizer, SnoptSolver, Solve, eq, ge, le,\n","                         MultibodyPlant, MultibodyPositionToGeometryPose,\n","                         Parser, PiecewisePolynomial, PiecewisePose,\n","                         Quaternion, Rgba, RigidTransform, RotationMatrix,\n","                         SceneGraph, Simulator, StartMeshcat, TrajectorySource)\n","from pydrake.all import (AbstractValue, AngleAxis, Concatenate, DiagramBuilder,\n","                         LeafSystem, MeshcatVisualizer, PiecewisePolynomial,\n","                         PiecewisePose, PointCloud, RigidTransform,\n","                         RollPitchYaw, Simulator, StartMeshcat)\n","\n","from manipulation import running_as_notebook, FindResource\n","from manipulation.scenarios import (AddIiwaDifferentialIK,\n","                                    MakeManipulationStation, AddMultibodyTriad,\n","                                    AddShape)\n","\n","from manipulation.meshcat_utils import AddMeshcatTriad\n","from pydrake.manipulation.planner import (\n","    DifferentialInverseKinematicsIntegrator,\n","    DifferentialInverseKinematicsParameters,\n","    DifferentialInverseKinematicsStatus)\n","from pydrake.manipulation.planner import DoDifferentialInverseKinematics\n","from manipulation.icp import IterativeClosestPoint\n","from pydrake.all import (Box, Sphere, PrismaticJoint, RevoluteJoint, SpatialInertia, UnitInertia) #PlanarJoint\n","from datetime import datetime\n","\n","if running_as_notebook:\n","    mpld3.enable_notebook()\n","\n","if True:\n","    global masks_saved\n","\n","def saat(msg=\"\"):\n","    print(str(datetime.now()), msg)\n","\n","saat()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["from pydrake.systems.sensors import (\n","    CameraInfo,\n","    ImageDepth32F,\n","    ImageLabel16I,\n","    ImageRgba8U,\n","    RgbdSensor,\n",")"]},{"cell_type":"code","execution_count":6,"metadata":{"cell_id":"0b1001fced2847b1ba8d109a14f9d735","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":32,"execution_start":1682523014272,"output_cleared":false,"source_hash":"fb85aab"},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:drake:Meshcat listening for connections at http://localhost:7000\n"]}],"source":["# print(str(datetime.now()))\n","# Start the visualizer.\n","meshcat = StartMeshcat()"]},{"cell_type":"code","execution_count":7,"metadata":{"cell_id":"57ae0f7151b641e2b436a252ba9380c7","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":8,"execution_start":1682523014303,"is_code_hidden":false,"output_cleared":false,"source_hash":"9b8c4e7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-11 22:03:31.471137 model directives defined\n"]}],"source":["model_directives = \"\"\"\n","directives:\n","- add_model:\n","    name: iiwa\n","    file: file://psets/psets/iiwa_description/iiwa7/iiwa7_with_box_collision.sdf\n","    # file: file://root/work/iiwa_description/iiwa7/iiwa7_with_box_collision.sdf\n","    # file: file://root/work/iiwa_description/iiwa7/iiwa7_no_collision.sdf\n","        \n","    # file: package://drake/manipulation/models/iiwa_description/iiwa7/iiwa7_no_collision.sdf \n","\n","    default_joint_positions:\n","        iiwa_joint_0_x: [0.0]\n","        iiwa_joint_0_y: [0.0]\n","        iiwa_joint_0_z: [0.0]\n","        iiwa_joint_1: [-1.57]\n","        iiwa_joint_2: [0.1]\n","        iiwa_joint_3: [0]\n","        iiwa_joint_4: [-1.2]\n","        iiwa_joint_5: [0]\n","        iiwa_joint_6: [1.6]\n","        iiwa_joint_7: [0]\n","- add_weld:\n","    parent: world\n","    child: iiwa::iiwa_link_0\n","    X_PC:\n","        translation: [0, -0.1, 0.0]\n","        rotation: !Rpy { deg: [0, 0, 0]}\n","- add_model:\n","    name: wsg\n","    file: package://drake/manipulation/models/wsg_50_description/sdf/schunk_wsg_50_with_tip.sdf\n","- add_weld:\n","    parent: iiwa::iiwa_link_7\n","    child: wsg::body\n","    X_PC:\n","        translation: [0, -0., 0.09]\n","        rotation: !Rpy { deg: [90, 0, 90]}\n","\n","- add_model:\n","    name: storage\n","    file: file://psets/psets/iiwa_description/iiwa7/storage.sdf\n","    # file: file://root/work/iiwa_description/iiwa7/iiwa7_with_box_collision.sdf\n","    # file: file://root/work/iiwa_description/iiwa7/iiwa7_no_collision.sdf\n","        \n","    # file: package://drake/manipulation/models/iiwa_description/iiwa7/iiwa7_no_collision.sdf \n","\n","    default_joint_positions:\n","        iiwa_joint_0_x: [5.0]\n","        iiwa_joint_0_y: [0.0]\n","        iiwa_joint_0_z: [0.0]\n","\n","- add_weld:\n","    parent: world\n","    child: storage::iiwa_link_0\n","    X_PC:\n","        translation: [0, 0.0, 0.0]\n","        rotation: !Rpy { deg: [0, 0, 0]}\n","# - add_model:\n","#     name: wsg2\n","#     file: package://drake/manipulation/models/wsg_50_description/sdf/schunk_wsg_50_with_tip.sdf\n","# - add_weld:\n","#     parent: storage::iiwa_link_0_original\n","#     child: wsg2::body\n","#     X_PC:\n","#         translation: [0, -0., 0.09]\n","#         rotation: !Rpy { deg: [90, 0, 90]}\n","- add_frame:\n","    name: bin0_origin\n","    X_PF:\n","      base_frame: world\n","      rotation: !Rpy { deg: [0.0, 70.0, 90.0 ]}\n","      translation: [-0.1, -1.1, 0.45]\n","\n","- add_model:\n","    name: bin0\n","    file: package://drake/examples/manipulation_station/models/bin.sdf\n","\n","- add_weld:\n","    parent: bin0_origin\n","    child: bin0::bin_base\n","\n","- add_frame:\n","    name: shelf1_goal\n","    X_PF:\n","      base_frame: world\n","      rotation: !Rpy { deg: [0.0, 0, 110.0 ]}\n","      translation: [0.95, -0.3, 0.48]\n","\n","- add_model:\n","    name: shelf1\n","    file: package://manipulation/shelves.sdf\n","\n","- add_weld:\n","    parent: shelf1_goal\n","    child: shelf1::shelves_body\n","\n","\n","- add_model:\n","    name: floor\n","    file: package://manipulation/floor.sdf\n","\n","- add_weld:\n","    parent: world\n","    child: floor::box\n","    X_PC:\n","        translation: [0, 0, -.5]\n","\n","# cracker box\n","# add cracker box\n","- add_model:\n","    name: cracker_box\n","    file: package://drake/manipulation/models/ycb/sdf/003_cracker_box.sdf\n","    default_free_body_pose:\n","        base_link_cracker:\n","            translation: [-0.1, -0.95, 0.45]\n","            rotation: !Rpy { deg: [-90, 0, 90] }\n","- add_model:\n","    name: cracker_box_2\n","    file: package://drake/manipulation/models/ycb/sdf/003_cracker_box.sdf\n","    default_free_body_pose:\n","        base_link_cracker:\n","            translation: [+0.0, -0.95, 0.45]\n","            rotation: !Rpy { deg: [-90, 0, 90] }\n","\n","# add cameras\n","- add_frame:\n","    name: camera3_origin\n","    X_PF:\n","        base_frame: world\n","        rotation: !Rpy { deg: [80., 150, -40]}\n","        translation: [0.25, -.5, .5]\n","\n","- add_model:\n","    name: camera3\n","    file: package://manipulation/camera_box.sdf\n","\n","- add_weld:\n","    parent: camera3_origin\n","    child: camera3::base\n","\n","- add_frame:\n","    name: camera4_origin\n","    X_PF:\n","        base_frame: world\n","        rotation: !Rpy { deg: [90, 180, 0]}\n","        translation: [0.0, -.4, 0.45]\n","\n","- add_model:\n","    name: camera4\n","    file: package://manipulation/camera_box.sdf\n","\n","- add_weld:\n","    parent: camera4_origin\n","    child: camera4::base\n","\n","- add_frame:\n","    name: camera5_origin\n","    X_PF:\n","        base_frame: world\n","        rotation: !Rpy { deg: [80., 210, 50]}\n","        translation: [-0.5, -.5, .5]\n","\n","- add_model:\n","    name: camera5\n","    file: package://manipulation/camera_box.sdf\n","\n","- add_weld:\n","    parent: camera5_origin\n","    child: camera5::base\n","\n","\"\"\" \n","\n","saat(\"model directives defined\")"]},{"attachments":{},"cell_type":"markdown","metadata":{"cell_id":"a7060f95806f4dc1b330fa02fbaa2487","deepnote_cell_type":"markdown"},"source":["# Putting it all together\n","\n","In the code above, we worked with a point cloud using functions.  To assemble this into a full-stack manipulation system, we need to specify the timing semantics of when those functions are called.  That's precisely what Drake's systems framework provides.  I've introduced two systems below: \n","- `MustardIterativeClosestPoint` system that takes the camera inputs and outputs the pose estimate using ICP, and \n","- `PickAndPlaceTrajectory` system that takes this pose estimate (and the state of the robot), computes the trajectory, and stores that trajectory in its Context so that it can output the instantaneous command.  \n","\n","We don't use a `TrajectorySource` here, because the trajectory is not known when we first build the Diagram... the information we need to plan the trajectory requires reading sensors at runtime."]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# Takes 3 point clouds (in world coordinates) as input, and outputs and estimated pose for the mustard bottle.\n","import pickle\n","\n","\n","class MaskSystem(LeafSystem):\n","    \n","    def __init__(self, rgbd_sensor):\n","        LeafSystem.__init__(self)\n","        self.DeclareAbstractInputPort(\n","            'rgb_image',\n","            rgbd_sensor.color_image_output_port().Allocate())\n","        self.DeclareAbstractInputPort(\n","            'depth_image',\n","            rgbd_sensor.depth_image_32F_output_port().Allocate())\n","\n","        self.DeclareAbstractOutputPort(\n","            'masked_depth_image',\n","            lambda: AbstractValue.Make([np.ndarray]),\n","            self.get_masks)\n","        self.color_image = None\n","        self.depth_image = None\n","\n","\n","    def colorFilter(self, img):\n","        # Define the threshold for how close to red a pixel needs to be\n","        red_threshold = 50  \n","\n","        # Loop through each pixel in the image and count the number of pixels that are close to red\n","        red_count = 0\n","        total_pixels = img.width * img.height\n","        for x in range(img.width):\n","            for y in range(img.height):\n","                r, g, b = img.getpixel((x, y))\n","                if r > g + red_threshold and r > b + red_threshold:\n","                    red_count += 1\n","\n","        # Calculate the proportion of red pixels\n","        proportion_red = red_count / total_pixels\n","\n","\n","        # print the proportion of red pixels\n","        print(proportion_red)\n","\n","        # Check if the majority of pixels are close to red\n","        if proportion_red > 0.25:\n","            return True\n","        else:\n","            return False\n","    \n","    def get_masks(self, context, output):\n","        thresh = 0.97\n","        # print(self.EvalAbstractInput(context, 'rgb_image').get_value())\n","        # res = np.repeat(rgb_image[np.newaxis, :, :], 5, axis=0)\n","\n","        self.color_image = self.GetInputPort('rgb_image').Eval(context).data\n","        self.color_image = Image.fromarray(np.uint8(self.color_image)).convert('RGB')\n","        self.depth_image = self.GetInputPort('depth_image').Eval(context).data\n","        self.depth_image = self.depth_image.squeeze()\n","\n","        # save color and depth images to file\n","        self.color_image.save(\"color_image.png\")\n","        \n","        # convert color_image to np array\n","        self.color_image = np.array(self.color_image)\n","\n","        # convert depth_image to np array\n","        self.depth_image = np.array(self.depth_image)\n","\n","\n","        # with torch.no_grad():\n","        #     prediction = self.model([Tf.to_tensor(color_image).to(self.device)])\n","\n","        # labels = list(prediction[0]['labels'].cpu().detach().numpy())\n","        # scores = list(prediction[0]['scores'].cpu().detach().numpy())\n","        # masks = prediction[0]['masks'].cpu().detach().numpy()\n","\n","\n","        rgbImages = []\n","        depthImages = []\n","\n","        masksArray = []\n","\n","        predicted_pieces = []\n","\n","        # masks = mask_generator.generate(self.color_image)\n","        \n","        print(\"before pcikle\")\n","        # save variable masks into a file using pickle\n","        # with open('masks.pkl', 'wb') as f:\n","        #     pickle.dump(masks, f)\n","\n","        print(\"after save\")\n","        # load variable masks from a file using pickle\n","        with open('masks.pkl', 'rb') as f:\n","            masks = pickle.load(f)\n","        print(\"after pickle\")\n","        \n","\n","        # plt.figure(figsize=(20,20))\n","        # plt.imshow(self.color_image)\n","        # show_anns(masks)\n","        # plt.axis('off')\n","        # plt.show()\n","        \n","        for i in range(len(masks)):\n","            \n","\n","            # if (masks[i]['stability_score'] > 0.99 and masks[i]['area'] > 10000):\n","            if True:\n","                # print(\"stab_score: \", masks[i]['stability_score'], \"area: \", masks[i]['area'])\n","                mask = np.array(masks[i][\"segmentation\"])\n","                \n","\n","                # mask the color image\n","                result = np.multiply(self.color_image, mask[:,:,np.newaxis])\n","\n","\n","                #mask the depth image \n","                depth_mask = np.multiply(self.depth_image, mask)\n","\n","                \n","                # sum all the values in mask \n","                # if sum is 0, then there is no object in the mask\n","                # if sum is not 0, then there is an object in the mask\n","                res1 = np.sum(mask)\n","\n","                res2 = np.sum(result)\n","\n","                # print(res1, res2)\n","                print(res1,res2)\n","\n","\n","                # sum the red channel of result\n","                res3 = np.sum(result[:,:,0]) / res1\n","                res4 = np.sum(result[:,:,1]) / res1\n","                res5 = np.sum(result[:,:,2]) / res1\n","\n","\n","                # countRed = cv2.countNonZero(result)\n","                # if countRed > 0: #choose whatever condition you want\n","                #     print(\"Red found\")\n","\n","                # add the masked depth image to the array\n","                masksArray.append(depth_mask)\n","                \n","\n","                # if res3 is greater than res4 and res5, then the object is red\n","                # if ( res3 > res4 and res3 > res5):\n","                if (self.colorFilter(result)):\n","                    # print(\"red is detected\")\n","                    plt.figure(figsize=(20,20))\n","                    plt.imshow(mask)\n","                    plt.axis('off')\n","\n","                    # # write stab score and area as a title of the plot with index i\n","                    # plt.title(\"i: \" + str(i) + \"stab_score: \" + str(masks[i]['stability_score']) + \" area: \" + str(masks[i]['area']) +\n","                    #           \"res3: \" + str(res3) + \"res4: \" + str(res4) + \"res5: \" + str(res5))\n","\n","                    plt.show()\n","\n","                    # append mask to Masksımages\n","       \n","                    depthImages.append(depth_mask)\n","\n","\n","                    # also plot the result\n","                    plt.figure(figsize=(20,20))\n","                    plt.imshow(result)\n","                    plt.axis('off')\n","                    plt.show()\n","                    \n","                    # append result to rgbImages\n","                    rgbImages.append(result)\n","                    predicted_pieces.append(0)\n","\n","        # for i, mask in enumerate(masks):\n","        #     if scores[i] < thresh:\n","        #         continue\n","        #     mask = mask.squeeze()\n","        #     mask = mask > 0.7  # Threshold mask so it only uses high confidence\n","        #     masked_depth_img = depth_image * mask\n","        #     masked_depth_imgs.append(masked_depth_img)\n","        #     predicted_pieces.append(self.get_piece_from_label(labels[i]))\n","\n","        print(\"calculating mask, rgb: \", self.color_image.size, \" depth: \", self.depth_image.shape)\n","        print(\"depth images: \", len(depthImages), \" rgb images: \", len(rgbImages))\n","        output.set_value([np.stack(depthImages, axis=0), predicted_pieces])"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["class CreatePointClouds(LeafSystem):\n","    \"\"\"\n","    System to convert masked depth images into pointclouds.\n","    \"\"\"\n","    # def __init__(self, rgbd_sensor, X_WC):\n","    def __init__(self, rgbd_sensor):\n","        LeafSystem.__init__(self)\n","\n","        self.cam_info = rgbd_sensor.depth_camera_info()\n","        self.rgbd_sensor = rgbd_sensor\n","\n","        # sensor_context = rgbd_sensor.GetMyMutableContextFromRoot(context)\n","        # self.X_WC = rgbd_sensor.body_pose_in_world_output_port().Eval(sensor_context)\n","\n","        RigidTransform()\n","\n","        self.DeclareAbstractInputPort(\n","            'depth_image_stack',\n","            AbstractValue.Make([np.ndarray]))\n","\n","        self.DeclareAbstractInputPort(\n","            'rgbd_sensor_body_pose',\n","            AbstractValue.Make(RigidTransform())\n","        )\n","\n","        self.DeclareAbstractOutputPort(\n","            'pcd_stack',\n","            lambda: AbstractValue.Make([np.ndarray]),\n","            self.calc_output)\n","\n","    def get_intrinsics(self):\n","        # read camera intrinsics\n","        cx = self.cam_info.center_x()\n","        cy = self.cam_info.center_y()\n","        fx = self.cam_info.focal_x()\n","        fy = self.cam_info.focal_y()\n","        return cx, cy, fx, fy\n","\n","    def project_depth_to_pC(self, depth_pixel):\n","        \"\"\"\n","        project depth pixels to points in camera frame\n","        using pinhole camera model\n","        Input:\n","            depth_pixels: numpy array of (nx3) or (3,)\n","        Output:\n","            pC: 3D point in camera frame, numpy array of (nx3)\n","        \"\"\"\n","        # switch u,v due to python convention\n","        v = depth_pixel[:,0]\n","        u = depth_pixel[:,1]\n","        Z = depth_pixel[:,2]\n","        cx, cy, fx, fy = self.get_intrinsics()\n","        X = (u-cx) * Z/fx\n","        Y = (v-cy) * Z/fy\n","        pC = np.c_[X,Y,Z]\n","        return pC\n","\n","    def get_pointcloud_np(self, depth_im, X_WC):\n","        u_range = np.arange(depth_im.shape[0])\n","        v_range = np.arange(depth_im.shape[1])\n","        depth_v, depth_u = np.meshgrid(v_range, u_range)\n","        depth_pnts = np.dstack([depth_u, depth_v, depth_im])\n","        depth_pnts = depth_pnts.reshape([depth_pnts.shape[0]*depth_pnts.shape[1], 3])\n","        pC = self.project_depth_to_pC(depth_pnts)\n","        p_C = pC[pC[:,2] > 0]\n","        p_W = X_WC.multiply(p_C.T).T\n","        return p_W\n","\n","    def get_drake_pcd(self, pcd_np, X_WC):\n","        N = pcd_np.shape[0]\n","        pcd = PointCloud(N, Fields(BaseField.kXYZs | BaseField.kRGBs))\n","        pcd.mutable_xyzs()[:] = pcd_np.T  # Want (3, N) while pcd_np is (N, 3)\n","        pcd.EstimateNormals(radius=0.1, num_closest=30)\n","        pcd.FlipNormalsTowardPoint(X_WC.translation())\n","        pcd = pcd.VoxelizedDownSample(voxel_size=0.002)\n","        return pcd\n","\n","\n","    def calc_output(self, context, output):\n","        # sensor_context = self.rgbd_sensor.GetMyMutableContextFromRoot(context)\n","        # X_WC = self.rgbd_sensor.body_pose_in_world_output_port().Eval(context)\n","\n","        X_WC = self.GetInputPort('rgbd_sensor_body_pose').Eval(context)\n","        depth_image_stack, pieces = self.GetInputPort('depth_image_stack').Eval(context)\n","        pcds = []\n","        for i in range(depth_image_stack.shape[0]):\n","            depth_image = depth_image_stack[i]\n","            pcd_np = self.get_pointcloud_np(depth_image, X_WC)\n","            pcd = self.get_drake_pcd(pcd_np, X_WC)\n","            pcds.append(pcd)\n","        print(\"in calc_output\")\n","        output.set_value([pcds, pieces])\n"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# Takes 3 point clouds (in world coordinates) as input, and outputs and estimated pose for the mustard bottle.\n","\n","class ICPSystem(LeafSystem):\n","    \n","    def __init__(self):\n","        LeafSystem.__init__(self)\n","        model_point_cloud = AbstractValue.Make(PointCloud(0))\n","        self.DeclareAbstractInputPort(\"cloud0\", model_point_cloud)\n","        self.DeclareAbstractInputPort(\"cloud1\", model_point_cloud)\n","        self.DeclareAbstractInputPort(\"cloud2\", model_point_cloud)\n","        self.inputs = []\n","\n","\n","\n","\n","        img1 = AbstractValue.Make(ImageRgba8U(480, 640, 0))\n","        depth1 = AbstractValue.Make(ImageDepth32F(480, 640, .0))\n","\n","        self.DeclareAbstractInputPort(\"image0\", img1)\n","        self.DeclareAbstractInputPort(\"depth0\", depth1)\n","\n","\n","        self.DeclareAbstractInputPort(\"image1\", img1)\n","        self.DeclareAbstractInputPort(\"depth1\", depth1)\n","\n","        self.DeclareAbstractInputPort(\"image2\", img1)\n","        self.DeclareAbstractInputPort(\"depth2\", depth1)\n","\n","        self.DeclareAbstractOutputPort(\n","            \"X_WO\", lambda: AbstractValue.Make(RigidTransform()),\n","            self.EstimatePose)\n","\n","        self.mustard = CrackerBoxPointCloud.CrackerBoxPointCloud()\n","        meshcat.SetObject(\"icp_scene\", self.mustard)\n","        meshcat.SetObject(\"icp_model\", self.mustard)\n","\n","\n","    def EstimatePose(self, context, output):\n","        pcd = []\n","        print(\"EstimatePose\")\n","        #global inputs\n","        for i in range(9):\n","            print(\"İnputs : \", self.inputs)\n","            #inputs[i] = (self.get_input_port(i).Eval(context))\n","\n","            self.inputs.append(self.get_input_port(i).Eval(context))\n","            print(self.inputs[i])\n","\n","\n","        for i in (3, 5, 7):\n","            # print input clouds\n","            # print(\"cloud\", i, cloud.xyzs())\n","\n","            # plot point clouds\n","\n","            '''\n","            # TODO: create image from xyzs\n","            # # Plot the two images.\n","            # plt.subplot(121)\n","            # plt.imshow(cloud)\n","            plt.title('cloud', i)\n","            # plt.subplot(122)\n","            plt.imshow(np.squeeze(self.inputs[i].data))\n","            plt.title('Depth image')\n","            # #mpld3.display()\n","            # plt.show()\n","            '''\n","\n","#                 cloud.Crop(lower_xyz=[-0.5, -1, 0.5], upper_xyz=[0.8, 0.8, 0.8]))\n","#                 cloud.Crop(lower_xyz=[-0.5, -0.87, 0.5], upper_xyz=[0.8, 0.8, 0.6]))\n","#               cloud.Crop(lower_xyz=[-0.5, -0.87, 0.4455], upper_xyz=[0.8, 0.8, 0.6]))\n","        for i in range(3):\n","            pcd.append(\n","                #cloud.Crop(lower_xyz=[.4, -.2, 0.001], upper_xyz=[.6, .3, .3]))\n","                #\n","                # cloud.Crop(lower_xyz=[-0.11, -0.96, 0.43], upper_xyz=[-0., -0.94, 0.46]))\n","                #cloud.Crop(lower_xyz=[-0.5, -0.87, 0.2], upper_xyz=[0.8, 0.8, 0.6]))\n","                #cloud.Crop(lower_xyz=[-0.5, -0.87, 0.45], upper_xyz=[0.1, -0.86, 0.6]))\n","                self.inputs[i].Crop(lower_xyz=[-0.17, -1.07, -2], upper_xyz=[0, 0, 0.6]))\n","\n","\n","\n","\n","        merged_pcd = Concatenate(pcd)\n","        down_sampled_pcd = merged_pcd.VoxelizedDownSample(voxel_size=0.005)\n","        meshcat.SetObject(\"icp_observations\",\n","                          down_sampled_pcd,\n","                          point_size=0.001)\n","\n","        # takes icp_observations + model cloud , returns icp?s\n","        X_WOhat, chat = IterativeClosestPoint(\n","            self.mustard.xyzs(),\n","            down_sampled_pcd.xyzs(),\n","            meshcat=meshcat,\n","            meshcat_scene_path=\"icp_scene\")\n","        print(\"X_WOhat = {}\".format(X_WOhat))\n","        output.set_value(X_WOhat)"]},{"cell_type":"code","execution_count":11,"metadata":{"cell_id":"0cdb9c88e09a42dda6bc9e0d0ae9741c","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":6,"execution_start":1682523014322,"source_hash":"879aaa39"},"outputs":[],"source":["def VectorizedMakeGripperFrames(X_G, X_O):\n","    \n","    \"\"\"\n","    Takes a partial specification with X_G[][\"initial\"] and X_O[][\"initial\"] and\n","    X_0[][\"goal\"], X_G[][\"pick\"] and returns a X_G[] and times[] with all of the pick and place\n","    frames populated.\n","    \"\"\"\n","\n","    \n","    # Now let's set the timing\n","    times = [dict() for x in range(2)]\n","    # X_GgraspO = RigidTransform( RotationMatrix.MakeXRotation(np.pi)  ,[0.03,0.05,0.06])\n","    # X_OGgrasp = X_GgraspO.inverse()\n","\n","\n","    X_GgraspGpregrasp = RigidTransform([0, -0.2, 0])\n","\n","    for i in range(2):\n","        # X_G[i][\"pick\"] = X_O[i][\"initial\"] @ X_OGgrasp\n","\n","        X_G[i][\"prepick\"] = X_G[i][\"pick\"] @ X_GgraspGpregrasp\n","        X_G[i][\"place\"] = X_O[i][\"goal\"]\n","        X_G[i][\"preplace\"] = X_G[i][\"place\"] @ X_GgraspGpregrasp\n","\n","        # I'll interpolate a halfway orientation by converting to axis angle and halving the angle.\n","        X_GprepickGpreplace = X_G[i][\"prepick\"].inverse() @ X_G[i][\"preplace\"]\n","        angle_axis = X_GprepickGpreplace.rotation().ToAngleAxis()\n","        X_GprepickGclearance = RigidTransform(\n","            AngleAxis(angle=angle_axis.angle() / 2.0, axis=angle_axis.axis()),\n","            X_GprepickGpreplace.translation() / 2.0 + np.array([0, 0, -0.3]),\n","        )\n","\n","    \n","        X_G[i][\"clearance\"] = RigidTransform( RotationMatrix.MakeXRotation(np.pi), [0.0, 0.0, 0.40])\n","\n","        if i == 0:\n","            times[i] = {\"initial\": 0}\n","            X_G[0][\"initial_to_prepick\"] = X_G[0][\"initial\"]\n","        else:\n","            times[i] = {\"initial\": times[i-1][\"postplace\"] + 4}\n","            X_G[i][\"initial\"] = X_G[i-1][\"postplace\"]\n","            # X_G[i][\"initial\"] = X_G[0][\"initial\"]\n","            X_G[i][\"initial_to_prepick\"] = RigidTransform( RotationMatrix.MakeXRotation(np.pi), [0.0, 0.0, 0.40])\n","\n","        X_GinitialGprepick = X_G[i][\"initial\"].inverse() @ X_G[i][\"prepick\"]\n","        times[i][\"initial_to_prepick\"] = times[i][\"initial\"] + (10.0 * np.linalg.norm(\n","            X_GinitialGprepick.translation()\n","        )) / 2\n","\n","        times[i][\"prepick\"] = times[i][\"initial\"] + 10.0 * np.linalg.norm(\n","            X_GinitialGprepick.translation()\n","        )\n","\n","        # Allow some time for the gripper to close.\n","        times[i][\"pick_start\"] = times[i][\"prepick\"] + 2.0\n","        times[i][\"pick_end\"] = times[i][\"pick_start\"] + 2.0\n","        X_G[i][\"pick_start\"] = X_G[i][\"pick\"]\n","        X_G[i][\"pick_end\"] = X_G[i][\"pick\"]\n","        times[i][\"postpick\"] = times[i][\"pick_end\"] + 2.0\n","        X_G[i][\"postpick\"] = X_G[i][\"prepick\"]\n","        time_to_from_clearance = 10.0 * np.linalg.norm(X_GprepickGclearance.translation())\n","        times[i][\"clearance\"] = times[i][\"postpick\"] + time_to_from_clearance\n","        times[i][\"preplace\"] = times[i][\"clearance\"] + time_to_from_clearance\n","        times[i][\"place_start\"] = times[i][\"preplace\"] + 2.0\n","        times[i][\"place_end\"] = times[i][\"place_start\"] + 2.0\n","        X_G[i][\"place_start\"] = X_G[i][\"place\"]\n","        X_G[i][\"place_end\"] = X_G[i][\"place\"]\n","        times[i][\"postplace\"] = times[i][\"place_end\"] + 2.0\n","        X_G[i][\"postplace\"] = X_G[i][\"preplace\"]\n","\n","\n","    return X_G, times"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# # write a function that returns the corner points of a given image , where 1's are objects and 0's are background\n","# def get_corners(img):\n","#     # img = cv2.imread(img)\n","#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","#     gray = np.float32(gray)\n","#     corners = cv2.goodFeaturesToTrack(gray, 100, 0.01, 10)\n","#     corners = np.int0(corners)\n","#     corner_list = []\n","#     for corner in corners:\n","#         x, y = corner.ravel()\n","#         corner_list.append([x,y])\n","#     return corner_list\n","\n"]},{"cell_type":"code","execution_count":13,"metadata":{"cell_id":"afe9cdcf8b14474cbb1ec690279494d2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":3,"execution_start":1682523014346,"source_hash":"a3f8e29e"},"outputs":[],"source":["def VectorizedMakeGripperPoseTrajectory(X_G, times):\n","    \"\"\"\n","    Constructs a gripper position trajectory from the plan \"sketch\".\n","    \"\"\"\n","\n","    sample_times = []\n","    poses = []\n","    for i in range(2):\n","        for name in [\n","            # \"initial\", \"initial_to_prepick\", \"prepick\", \"pick_start\", \"pick_end\", \"postpick\",\n","            \"initial\", \"prepick\", \"pick_start\", \"pick_end\", \"postpick\",\n","                    # \"clearance\", \"preplace\", \"place_start\", \"place_end\",\n","                    \"preplace\", \"place_start\", \"place_end\",\n","                    \"postplace\"]:\n","            sample_times.append(times[i][name])\n","            poses.append(X_G[i][name])\n","        \n","            # poses.append(X_G[0][\"initial\"])\n","            \n","        # if i != 1:\n","        #     sample_times.append(times[i][\"postplace\"] + 3)\n","        #     poses.append(X_G[i][\"clearance\"])\n","\n","    return PiecewisePose.MakeLinear(sample_times, poses)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-11 22:03:31.997637 \n"]}],"source":["def MakeStorageTrajectory(X_G, times):\n","    sample_times = []\n","    poses = []\n","    for name in [\"initial\", \"p0\", \"p1\"]:\n","        sample_times.append(times[name])\n","        poses.append(X_G[name])\n","            \n","    return PiecewisePose.MakeLinear(sample_times, poses)\n","saat()"]},{"cell_type":"code","execution_count":15,"metadata":{"cell_id":"91e4ffc53ec34c02b3b3b4538c9235e3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":2,"execution_start":1682523014346,"source_hash":"2aa09e9a"},"outputs":[],"source":["def VectorizedMakeGripperCommandTrajectory(times):\n","    opened = np.array([0.107])\n","    closed = np.array([0.0])\n","\n","    traj_wsg_command = PiecewisePolynomial.FirstOrderHold(\n","        [times[0][\"initial\"], times[0][\"pick_start\"]], np.hstack([[opened], [opened]]))\n","\n","\n","    traj_wsg_command.AppendFirstOrderSegment(times[0][\"pick_end\"], closed)\n","    traj_wsg_command.AppendFirstOrderSegment(times[0][\"place_start\"], closed)\n","    traj_wsg_command.AppendFirstOrderSegment(times[0][\"place_end\"], opened)\n","    traj_wsg_command.AppendFirstOrderSegment(times[0][\"postplace\"], opened)\n","\n","\n","    for i in range(1, 2):\n","        traj_wsg_command.AppendFirstOrderSegment(times[i][\"pick_start\"], opened)\n","        traj_wsg_command.AppendFirstOrderSegment(times[i][\"pick_end\"], closed)\n","        #traj_wsg_command.AppendFirstOrderSegment(times[\"place_start2\"], closed)\n","        traj_wsg_command.AppendFirstOrderSegment(times[i][\"place_end\"], closed)\n","        traj_wsg_command.AppendFirstOrderSegment(times[i][\"postplace\"], opened)\n","\n","\n","\n","    return traj_wsg_command"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# import matplotlib.pyplot as plt \n","# plt.imshow(np.squeeze(icp.inputs[5].data))\n","# plt.title('Depth image')\n","\n","# res = icp.inputs[5].data\n","\n","# masks = mask_generator.generate(res[:,:,:3])\n","# for i in range(len(masks)):\n","#     if (masks[i]['stability_score'] > 0.99 and masks[i]['area'] > 30000 ):\n","#         image = np.array(masks[i][\"segmentation\"])\n","#         plt.figure(figsize=(20,20))\n","#         plt.imshow(image)\n","#         plt.axis('off')\n","#         plt.show()\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"cell_id":"77af11cbb8814e2f95d0992077bc0ba3","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4,"execution_start":1682523014373,"source_hash":"b3d85f2f"},"outputs":[],"source":["X_G = 0\n","X_G2 = 0\n","class PickAndPlaceTrajectory3(LeafSystem):\n","    def __init__(self, plant):\n","        LeafSystem.__init__(self)\n","        self._gripper_body_index = plant.GetBodyByName(\"body\", plant.GetModelInstanceByName(\"wsg\")).index()\n","        # self._gripper_body_index2 = plant.GetBodyByName(\"body\", plant.GetModelInstanceByName(\"wsg2\")).index()\n","        \n","        self.DeclareAbstractInputPort(\n","            \"body_poses\", AbstractValue.Make([RigidTransform()]))\n","        \n","        self._iiwa_link_0_original_body_index = plant.GetBodyByName(\"iiwa_link_0_original\", plant.GetModelInstanceByName(\"iiwa\")).index()\n","        self._iiwa_link_0_original_body_index2 = plant.GetBodyByName(\"iiwa_link_0_z\", plant.GetModelInstanceByName(\"storage\")).index()\n","        \n","        \n","        self.DeclareAbstractInputPort(\"X_WO\",\n","                                      AbstractValue.Make(RigidTransform()))\n","\n","        self.DeclareInitializationUnrestrictedUpdateEvent(self.Plan)\n","        self._traj_X_G_index = self.DeclareAbstractState(\n","            AbstractValue.Make(PiecewisePose()))\n","        self._traj_wsg_index = self.DeclareAbstractState(\n","            AbstractValue.Make(PiecewisePolynomial()))\n","        \n","        self._traj_X_G_index2 = self.DeclareAbstractState(\n","            AbstractValue.Make(PiecewisePose()))\n","        self._traj_wsg_index2 = self.DeclareAbstractState(\n","            AbstractValue.Make(PiecewisePolynomial()))\n","\n","        self.DeclareAbstractOutputPort(\n","            \"X_WG\", lambda: AbstractValue.Make(RigidTransform()),\n","            self.CalcGripperPose)\n","        \n","        self.DeclareAbstractOutputPort(\n","            \"X_WG2\", lambda: AbstractValue.Make(RigidTransform()),\n","            self.CalcGripperPose2)\n","        \n","        self.DeclareVectorOutputPort(\"wsg_position\", 1, self.CalcWsgPosition)\n","        self.DeclareVectorOutputPort(\"wsg_position2\", 1, self.CalcWsgPosition2)\n","\n","    def Plan(self, context, state):\n","        # X_G = {\n","        #     \"initial\":\n","        #         self.get_input_port(0).Eval(context)\n","        #         [int(self._gripper_body_index)]\n","        # }\n","\n","        # X_O = {\n","        #     \"initial\": self.get_input_port(1).Eval(context), \n","        #     #\"goal\": RigidTransform( [1.15, 0.0, 0.45])\n","        #     \"goal\": RigidTransform(RotationMatrix.MakeXRotation(np.pi), [1.0, 0.0, 0.450])\n","        # }\n","        # print(\"body poses\", self.get_input_port(0).Eval(context))\n","        \n","        global X_G\n","        global X_G2\n","        \n","        X_O = [dict() for x in range(2)]\n","        X_O2 = [dict() for x in range(2)]\n","\n","\n","        \n","        X_G = [dict() for x in range(2)]\n","        X_G2 = [dict() for x in range(2)]\n","\n","        for i in range(2):\n","            X_O[i][\"initial\"] =  self.get_input_port(1).Eval(context)\n","\n","            # X_O[i][\"initial\"]= RigidTransform(RotationMatrix.MakeXRotation(np.pi), [1.0, 0.0, 0.500])\n","            X_O[i][\"goal\"] = RigidTransform(RotationMatrix.MakeXRotation(np.pi), [1.0, 0.0, 0.500])\n","\n","            X_O2[i][\"initial\"] =  RigidTransform( [4.7, 4.5, 0.500])\n","            X_O2[i][\"goal\"] = RigidTransform( [5.3, 5.5, 0.500])    \n","\n","        X_G[0][\"initial\"] = self.get_input_port(0).Eval(context)[int(self._gripper_body_index)]      \n","        \n","        # !!!!!!!!!        \n","        # X_G2[0][\"initial\"] = self.get_input_port(0).Eval(context)[int(self._gripper_body_index2)]\n","        X_G2[0][\"initial\"] = self.get_input_port(0).Eval(context)[int(self._gripper_body_index)]\n","\n","\n","        # print(\"X_G[0][initial]\", X_G[0][\"initial\"], \"X_G2[0][initial]\", X_G2[0][\"initial\"])\n","        print(\"X_O[0][initial]\", X_O[0][\"initial\"], \"X_O2[0][initial]\", X_O2[0][\"initial\"])\n","        # ================== 1st trajectory ==================\n","\n","        # trans= self.get_input_port(0).Eval(context)[int(self._iiwa_link_0_original_body_index)]\n","        # tr = trans.translation()\n","\n","        # tr = tr+[-0.5, 0, 0]\n","        # trans.set_translation(tr)\n","\n","        # trans = trans @ RigidTransform(RotationMatrix.MakeXRotation(np.pi / 2.0), [0, 0, 0])\n","\n","        # trans.set_rotation(trans.rotation() @ RotationMatrix.MakeYRotation(np.pi))\n","\n","        # X_O[1][\"goal\"] = trans # self.get_input_port(0).Eval(context)[int(self._iiwa_link_0_original_body_index)]\n","\n","\n","      #  rotation: !Rpy { deg: [0.0, 70.0, 180.0 ]}\n","      #  translation: [1.2, 0.05, 0.45]\n","\n","        for i in range(2):\n","            X_GgraspO = RigidTransform( RotationMatrix.MakeXRotation(np.pi)  ,[0.03,0.03,0.06])\n","            X_OGgrasp = X_GgraspO.inverse()\n","            # X_GgraspO2 = RigidTransform( RotationMatrix.MakeYRotation(np.pi)  ,[-0.03,-0.03,-0.06])\n","            # X_OGgrasp2 = X_GgraspO.inverse()\n","\n","            X_G[i][\"pick\"] = X_O[i][\"initial\"] @ X_OGgrasp\n","            X_G2[i][\"pick\"] = RigidTransform([5, 4.5, 0.0])\n","            # X_G[i][\"pick\"].set_translation(X_G[i][\"pick\"].translation()+[0, 0, 0.47])\n","\n","            # hardcoded\n","            # X_G[i][\"pick\"] = RigidTransform(RotationMatrix.MakeXRotation(np.pi)  ,[-0.2,-1.0,0.5])\n","\n","        #tmp = X_O[\"goal\"] @ X_OGgrasp\n","        # I'll interpolate a halfway orientation by converting to axis angle and halving the angle.\n","\n","        # X_GprepickGpreplace = X_G[\"pick\"].inverse() @ tmp\n","        # angle_axis = X_GprepickGpreplace.rotation().ToAngleAxis()\n","        # X_GprepickGclearance = RigidTransform(\n","        #     AngleAxis(angle=angle_axis.angle() / 2.0, axis=angle_axis.axis()),\n","        #     X_GprepickGpreplace.translation() / 2.0 + np.array([0.8, -1, 2]),\n","        # )\n","        \n","        # # the arm should rotate to avoid collision, the Z rotation is for that!\n","        # X_GprepickGclearance.set_rotation(X_GprepickGclearance.rotation() @ RotationMatrix.MakeZRotation(-np.pi / 2.0))\n","        # tmpReal = X_G[\"pick\"] @ X_GprepickGclearance\n","\n","\n","        # # hardcoded\n","        # tmpReal = RigidTransform( RotationMatrix.MakeXRotation(np.pi), [0.0, 0.0, 0.40])\n","\n","\n","\n","        # X_G[\"place\"] = X_O[\"goal\"] @ X_OGgrasp\n","        \n","        #hardcode\n","\n","        for i in range(2):\n","            X_G[i][\"place\"] = X_O[i][\"goal\"]\n","            X_G2[i][\"place\"] = X_O2[i][\"goal\"]\n","        \n","        # degisicek\n","        times = VectorizedMakeGripperFrames(X_G, X_O)[1]\n","        times2 = VectorizedMakeGripperFrames(X_G2, X_O2)[1]\n","\n","        for i in range(1):\n","            if True:  # Useful for debugging\n","                AddMeshcatTriad(meshcat, \"X_Oinitial \" + str(i), X_PT=X_O[i][\"initial\"])\n","                # AddMeshcatTriad(meshcat, \"X_goal \"+ str(i), X_PT=X_O2[i][\"goal\"])\n","\n","\n","                # AddMeshcatTriad(meshcat, f\"gripper \"+ str(i), X_PT=X_G2[i][\"initial\"])\n","                # AddMeshcatTriad(meshcat, \"X_Gprepick \" + str(i), X_PT=X_G2[i][\"prepick\"])\n","                # AddMeshcatTriad(meshcat, \"X_Gpick_start \" + str(i), X_PT=X_G2[i][\"pick_start\"])\n","                # AddMeshcatTriad(meshcat, \"X_Gpick_end \" + str(i), X_PT=X_G2[i][\"pick_end\"])\n","                # AddMeshcatTriad(meshcat, \"X_Gpostpick \" + str(i), X_PT=X_G2[i][\"postpick\"])\n","                # AddMeshcatTriad(meshcat, \"X_Gclearance \" + str(i), X_PT=X_G2[i][\"clearance\"])\n","                # AddMeshcatTriad(meshcat, \"X_Gpreplace \" + str(i), X_PT=X_G2[i][\"preplace\"])\n","                # AddMeshcatTriad(meshcat, \"X_Gplace_start \" + str(i), X_PT=X_G2[i][\"place_start\"])\n","                # AddMeshcatTriad(meshcat, \"X_Gplace_end \" + str(i), X_PT=X_G2[i][\"place_end\"])\n","                # AddMeshcatTriad(meshcat, \"X_Gpostplace \" + str(i), X_PT=X_G2[i][\"postplace\"])\n","\n","                # AddMeshcatTriad(meshcat, f\"tmpReal \"+ str(i), X_PT=tmpReal)\n","\n","\n","\n","        print(f\"Planned {times[1]['postplace']} second trajectory.\")\n","\n","        \n","        traj_X_G = VectorizedMakeGripperPoseTrajectory(X_G, times)\n","        traj_X_G2 = VectorizedMakeGripperPoseTrajectory(X_G2, times2)\n","\n","\n","        traj_wsg_command = VectorizedMakeGripperCommandTrajectory(times)\n","        # traj_wsg_command2 = VectorizedMakeGripperCommandTrajectory(times2)\n","\n","\n","        state.get_mutable_abstract_state(int(\n","            self._traj_X_G_index)).set_value(traj_X_G)\n","        state.get_mutable_abstract_state(int(\n","            self._traj_wsg_index)).set_value(traj_wsg_command)\n","        \n","        state.get_mutable_abstract_state(int(\n","            self._traj_X_G_index2)).set_value(traj_X_G2)\n","        \n","        # state.get_mutable_abstract_state(int(\n","        #     self._traj_wsg_index2)).set_value(traj_wsg_command2)\n","\n","    def start_time(self, context):\n","        return context.get_abstract_state(\n","            int(self._traj_X_G_index)).get_value().start_time()\n","\n","    def end_time(self, context):\n","        return context.get_abstract_state(\n","            int(self._traj_X_G_index)).get_value().end_time()\n","\n","    def CalcGripperPose(self, context, output):\n","        # Evaluate the trajectory at the current time, and write it to the\n","        # output port.\n","        output.set_value(context.get_abstract_state(int(\n","            self._traj_X_G_index)).get_value().GetPose(context.get_time()))\n","\n","    def CalcWsgPosition(self, context, output):\n","        # Evaluate the trajectory at the current time, and write it to the\n","        # output port.\n","        output.SetFromVector(\n","            context.get_abstract_state(int(\n","                self._traj_wsg_index)).get_value().value(context.get_time()))\n","    \n","    def start_time2(self, context):\n","        return context.get_abstract_state(\n","            int(self._traj_X_G_index2)).get_value().start_time()\n","\n","    def end_time2(self, context):\n","        return context.get_abstract_state(\n","            int(self._traj_X_G_index2)).get_value().end_time()\n","\n","    def CalcGripperPose2(self, context, output):\n","        # Evaluate the trajectory at the current time, and write it to the\n","        # output port.\n","        output.set_value(context.get_abstract_state(int(\n","            self._traj_X_G_index2)).get_value().GetPose(context.get_time()))\n","\n","    def CalcWsgPosition2(self, context, output):\n","        # Evaluate the trajectory at the current time, and write it to the\n","        # output port.\n","        output.SetFromVector(\n","            context.get_abstract_state(int(\n","                self._traj_wsg_index2)).get_value().value(context.get_time()))"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["\n","class StoragePlanner(LeafSystem):\n","    def __init__(self, plant):\n","        LeafSystem.__init__(self)\n","        # self._gripper_body_index = plant.GetBodyByName(\"body\", plant.GetModelInstanceByName(\"wsg\")).index()\n","        # self._gripper_body_index2 = plant.GetBodyByName(\"body\", plant.GetModelInstanceByName(\"wsg2\")).index()\n","        \n","        self.DeclareAbstractInputPort(\n","            \"body_poses\", AbstractValue.Make([RigidTransform()])) # body pose 2 plannera input olarak geliyor\n","        \n","        self._iiwa_link_0_original_body_index2 = plant.GetBodyByName(\"iiwa_link_0_z\", plant.GetModelInstanceByName(\"storage\")).index()\n","        \n","        \n","\n","        self.DeclareInitializationUnrestrictedUpdateEvent(self.Plan)\n","\n","\n","        \n","        self._traj_X_WS_index = self.DeclareAbstractState(\n","            AbstractValue.Make(PiecewisePose()))\n","        self._traj_wsg_index = self.DeclareAbstractState(\n","            AbstractValue.Make(PiecewisePolynomial()))\n","        \n","        self.DeclareAbstractOutputPort(\n","            \"X_WG\", lambda: AbstractValue.Make(RigidTransform()),\n","            self.CalcGripperPose)\n","        \n","        self.DeclareVectorOutputPort(\"wsg_position\", 1, self.CalcWsgPosition)\n","    def Plan(self, context, state):\n","        # set some points for storage to move\n","        X_WS = dict()\n","        X_WS[\"initial\"] = self.get_input_port(0).Eval(context)[int(self._iiwa_link_0_original_body_index2)]\n","        X_WS[\"p0\"] = RigidTransform( [2.0, 1.5, 0.0])\n","        X_WS[\"p1\"] = RigidTransform([-2.0, 3.0, 0.0])\n","\n","\n","        times = dict()\n","        times[\"initial\"] = 0.0\n","        times[\"p0\"] = 4.0\n","        times[\"p1\"] = 10.0\n","\n","\n","        if True:  # Useful for debugging\n","            AddMeshcatTriad(meshcat, \"X_WS[initial]\", X_PT=X_WS[\"initial\"])\n","            AddMeshcatTriad(meshcat, \"X_WS[p0]\", X_PT=X_WS[\"p0\"])\n","            AddMeshcatTriad(meshcat, f\"X_WS[p1] \", X_PT=X_WS[\"p1\"])\n","\n","        \n","        traj_X_WS = MakeStorageTrajectory(X_WS, times)\n","\n","        opened = np.array([0.107])\n","        closed = np.array([0.0])\n","\n","        traj_wsg_command = PiecewisePolynomial.FirstOrderHold(\n","            [times[\"initial\"], times[\"p0\"]], np.hstack([[opened], [opened]]))\n","\n","\n","        traj_wsg_command.AppendFirstOrderSegment(times[\"p1\"], closed)\n","\n","\n","\n","        state.get_mutable_abstract_state(int(\n","            self._traj_X_WS_index)).set_value(traj_X_WS)\n","        state.get_mutable_abstract_state(int(\n","            self._traj_wsg_index)).set_value(traj_wsg_command)      \n","\n","        \n","    def CalcWsgPosition(self, context, output):\n","        # Evaluate the trajectory at the current time, and write it to the\n","        # output port.\n","        output.SetFromVector(\n","            context.get_abstract_state(int(\n","                self._traj_wsg_index)).get_value().value(context.get_time()))\n","    def start_time(self, context):\n","        return context.get_abstract_state(\n","            int(self._traj_X_WS_index)).get_value().start_time()\n","\n","    def end_time(self, context):\n","        return context.get_abstract_state(\n","            int(self._traj_X_WS_index)).get_value().end_time()\n","\n","    def CalcGripperPose(self, context, output):\n","        # Evaluate the trajectory at the current time, and write it to the\n","        # output port.\n","        output.set_value(context.get_abstract_state(int(\n","            self._traj_X_WS_index)).get_value().GetPose(context.get_time()))\n"]},{"cell_type":"code","execution_count":19,"metadata":{"cell_id":"ea38e1ebe17441f08b9edfce94b90fd2","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":10,"execution_start":1682523014391,"is_code_hidden":true,"source_hash":"806fa7c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-11 22:03:32.399409 setup function is defined\n"]}],"source":["def add_freebox(plant):\n","    #      ###################################################\n","    #     # Place the stand/freebox\n","    #     ###################################################\n","    # freebox ds= AddShape(plant,\n","    #                     Box(0.3, 0.3, 0.1),\n","    #                     \"freebox\",\n","    #                     color=[0, 1, 0, 1.0])\n","    # plant.SetDefaultFreeBodyPose(plant.GetBodyByName(\"freebox\"),RigidTransform([0, 0, 0.5]))\n","\n","    #     # weld the freebox to the ground\n","    #     # plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"freebox\"))\n","\n","    #     # freebox_joint = plant.AddJoint(PlanarJoint(\n","    #     #     # \"freebox_joint\", plant.GetFrameByName(\"ground\", ground),\n","    #     #     \"freebox_joint\", plant.world_frame() ,\n","    #     #     plant.GetFrameByName(\"freebox\")))\n","\n","    #     # we cannot connect the both ports of the freebox controller and iiwa's controller\n","    #     # so we need to incorporate the control of the frebox into iiwa's controller through joint actuator\n","    #     # however we cannot add actuators for planar joints, so we need to use the\n","    #     # workaround of creating two prismatic and one revolute joint and so on\n","    #     # but there can be only one joint between two things.\n","    #     # So we need to create point objects (so called false bodies) to add all joints!\n","    #     # See https://stackoverflow.com/questions/71477852/how-to-add-jointactuator-for-planarjoint\n","\n","    iiwa = plant.GetModelInstanceByName(\"iiwa\")\n","\n","    # freebox_body_x = plant.AddRigidBody(\n","    #         \"freebox_body_x\", iiwa,\n","    #         SpatialInertia(0, [0, 0, 0], UnitInertia(0, 0, 0)))\n","\n","\n","#     freebox_body_y = plant.AddRigidBody(\n","#             \"freebox_body_y\", iiwa,\n","#             SpatialInertia(0, [0, 0, 0], UnitInertia(0, 0, 0)))\n","\n","# freebox_joint_x = plant.AddJoint(PrismaticJoint(\n","#         \"freebox_joint_x\", plant.world_frame(), controller_plant.GetFrameByName(\"iiwa_link_0_x\"), #freebox_body_x.body_frame(), #plant.GetFrameByName(\"freebox\"),\n","#         [1, 0, 0]))\n","# plant.AddJointActuator(\"freebox_joint_x_actuator\", freebox_joint_x)\n","\n","#     freebox_joint_y = plant.AddJoint(PrismaticJoint(\n","#             \"freebox_joint_y\", plant.GetFrameByName(\"freebox\"), freebox_body_y.body_frame(),\n","#             [0, 1, 0]))\n","#     plant.AddJointActuator(\"freebox_joint_y_actuator\", freebox_joint_y)\n","\n","#     freebox_body_theta = plant.AddJoint(RevoluteJoint(\n","#             \"freebox_body_theta\", freebox_body_y.body_frame(), plant.GetFrameByName(\"iiwa_link_0\"),\n","#             [0, 0, 1]))\n","#     plant.AddJointActuator(\"freebox_body_theta_actuator\", freebox_body_theta)\n","\n","\n","# freebox_joint.set_default_translation([0, 0,])\n","\n","\n","# plant.WeldFrames(plant.GetFrameByName(\"freebox\"), plant.GetFrameByName(\"iiwa_link_0\"))\n","def setup(plant):\n","    # add the ground!\n","    ground = AddShape(\n","        plant, Box(20.0, 20.0, 0.1), \"ground\", color=[0.7539, 0.7539, 0.7539, 1.0]\n","    )\n","    plant.WeldFrames(\n","        plant.world_frame(),\n","        plant.GetFrameByName(\"ground\", ground),\n","        RigidTransform([0, 0, -0.1]),\n","    )\n","\n","    # place the books!\n","    # plant.SetDefaultFreeBodyPose(plant.GetBodyByName(\"base_link_cracker\"), X_O['initial'])\n","    # plant.SetDefaultFreeBodyPose(plant.GetBodyByName(\"base_link_sugar\"), X_O2['initial'])\n","\n","    ###################################################\n","    # The book storage of iiwa should be added here\n","    ###################################################\n","    # wall01 = AddShape(plant,\n","    #                     Box(1., 1., .1),\n","    #                     \"wall01\",\n","    #                     color=[0, 1, 0, 1.0])\n","    # plant.SetDefaultFreeBodyPose(plant.GetBodyByName(\"wall01\"),RigidTransform([4, 4, 6]))\n","\n","    width = 0.15\n","    depth = 0.1\n","    height = 0.2\n","    thick = 0.004\n","    thickness = thick\n","    m = 2  # should be an positive odd number\n","    n = 2  # should be an positive integer\n","    storageRT = RigidTransform([0.5, 0, 0])\n","    storages = []\n","    for i in range(0, m):\n","        for j in range(0, n):\n","            storages.append(\n","                AddShape(\n","                    plant,\n","                    Box(width, depth, thick),\n","                    \"storage_bottom\" + \"_\" + str(i) + \"_\" + str(j),\n","                    color=[0.5, 0, 0.5, 1.0],\n","                )\n","            )\n","            list_index = (i * n + j) * 5\n","            first_dimension_difference = width + 2 * thickness\n","            first_dimension_index_difference = i - 0\n","\n","            second_dimension_difference = depth + 2 * thickness\n","            second_dimension_index_difference = j - int(n / 2)\n","\n","            # plant.WeldFrames(plant.GetFrameByName(\"iiwa_link_0\"),\n","            print(\n","                \"frame\",\n","                plant.GetFrameByName(\n","                    \"iiwa_link_0_z\", plant.GetModelInstanceByName(\"storage\")\n","                ),\n","            )\n","            print(\"model instance\", plant.GetModelInstanceByName(\"storage\"))\n","            print(\n","                \"frame\",\n","                plant.GetFrameByName(\n","                    \"storage_bottom\" + \"_\" + str(i) + \"_\" + str(j), storages[list_index]\n","                ),\n","            )\n","            print(\n","                \"rigid transform\",\n","                RigidTransform(\n","                    [\n","                        -(width / 2 + 0.15)\n","                        - (width + 2 * thickness) * first_dimension_index_difference,\n","                        -(depth + 2 * thickness) * second_dimension_index_difference,\n","                        0,\n","                    ]\n","                ),\n","            )\n","\n","            plant.WeldFrames(\n","                plant.GetFrameByName(\n","                    \"iiwa_link_0_original\", plant.GetModelInstanceByName(\"storage\")\n","                ),\n","                plant.GetFrameByName(\n","                    \"storage_bottom\" + \"_\" + str(i) + \"_\" + str(j), storages[list_index]\n","                ),\n","                RigidTransform(\n","                    [\n","                        -(width / 2 + 0.15)\n","                        - (width + 2 * thickness) * first_dimension_index_difference,\n","                        -(depth + 2 * thickness) * second_dimension_index_difference,\n","                        0,\n","                    ]\n","                ),\n","            )\n","\n","            # storage_joint = plant.AddJoint(\n","            #     RevoluteJoint(\n","            #         \"storage_theta\",\n","            #         plant.GetFrameByName(\n","            #             \"storage_bottom\" + \"_\" + str(i) + \"_\" + str(j)\n","            #         ),\n","            #         plant.GetFrameByName(\n","            #             \"iiwa_link_0_z\", plant.GetModelInstanceByName(\"storage\")\n","            #         ),\n","            #         [0, 0, 1],\n","            #     )\n","            # )\n","            \n","            # plant.AddJointActuator(\"freebox_body_theta_actuator\", freebox_body_theta)\n","\n","            storages.append(\n","                AddShape(\n","                    plant,\n","                    Box(height, depth, thick),\n","                    \"storage_side01\" + \"_\" + str(i) + str(\"_\") + str(j),\n","                    color=[1, 1, 0, 1.0],\n","                )\n","            )\n","            # n1 = \"storage_bottom\" +\"_\" + str(i) +\"_\" + str(j)\n","            n1 = \"storage_bottom\" + \"_\" + str(i) + \"_\" + str(j)\n","            n2 = \"storage_side01\" + \"_\" + str(i) + str(\"_\") + str(j)\n","            plant.WeldFrames(\n","                plant.GetFrameByName(n1, storages[list_index]),\n","                plant.GetFrameByName(n2, storages[list_index + 1]),\n","                RigidTransform(\n","                    RotationMatrix.MakeYRotation(np.pi / 2.0),\n","                    [-(width / 2 + thick / 2), 0, height / 2 + thick / 2],\n","                ),\n","            )\n","\n","            storages.append(\n","                AddShape(\n","                    plant,\n","                    Box(width, height, thick),\n","                    \"storage_side02\" + \"_\" + str(i) + str(\"_\") + str(j),\n","                    color=[0, 1, 1, 1.0],\n","                )\n","            )\n","            plant.WeldFrames(\n","                plant.GetFrameByName(\n","                    \"storage_bottom\" + \"_\" + str(i) + \"_\" + str(j), storages[list_index]\n","                ),\n","                plant.GetFrameByName(\n","                    \"storage_side02\" + \"_\" + str(i) + str(\"_\") + str(j),\n","                    storages[list_index + 2],\n","                ),\n","                RigidTransform(\n","                    RotationMatrix.MakeXRotation(np.pi / 2.0),\n","                    [0, depth / 2 + thick / 2, height / 2 + thick / 2],\n","                ),\n","            )\n","            storages.append(\n","                AddShape(\n","                    plant,\n","                    Box(width, height, thick),\n","                    \"storage_side03\" + \"_\" + str(i) + str(\"_\") + str(j),\n","                    color=[0, 1, 1, 0.5],\n","                )\n","            )\n","            plant.WeldFrames(\n","                plant.GetFrameByName(\n","                    \"storage_bottom\" + \"_\" + str(i) + \"_\" + str(j), storages[list_index]\n","                ),\n","                plant.GetFrameByName(\n","                    \"storage_side03\" + \"_\" + str(i) + str(\"_\") + str(j),\n","                    storages[list_index + 3],\n","                ),\n","                RigidTransform(\n","                    RotationMatrix.MakeXRotation(np.pi / 2.0),\n","                    [0, -depth / 2 - thick / 2, height / 2 + thick / 2],\n","                ),\n","            )\n","            storages.append(\n","                AddShape(\n","                    plant,\n","                    Box(height, depth, thick),\n","                    \"storage_side04\" + \"_\" + str(i) + str(\"_\") + str(j),\n","                    color=[1, 0, 0, 1.0],\n","                )\n","            )\n","            plant.WeldFrames(\n","                plant.GetFrameByName(\n","                    \"storage_bottom\" + \"_\" + str(i) + str(\"_\") + str(j),\n","                    storages[list_index],\n","                ),\n","                plant.GetFrameByName(\n","                    \"storage_side04\" + \"_\" + str(i) + str(\"_\") + str(j),\n","                    storages[list_index + 4],\n","                ),\n","                RigidTransform(\n","                    RotationMatrix.MakeYRotation(np.pi / 2.0),\n","                    [width / 2 + thick / 2, 0, height / 2 + thick / 2],\n","                ),\n","            )\n","\n","\n","saat(\"setup function is defined\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["def CustomAddWsg(plant,\n","           iiwa_model_instance,\n","           roll=np.pi / 2.0,\n","           welded=False,\n","           sphere=False):\n","    parser = Parser(plant)\n","    if welded:\n","        if sphere:\n","            gripper = parser.AddModelFromFile(\n","                FindResource(\"models/schunk_wsg_50_welded_fingers_sphere.sdf\"),\n","                \"gripper\")\n","        else:\n","            gripper = parser.AddModelFromFile(\n","                FindResource(\"models/schunk_wsg_50_welded_fingers.sdf\"),\n","                \"gripper\")\n","    else:\n","        gripper = parser.AddModelFromFile(\n","            FindResourceOrThrow(\n","                \"drake/manipulation/models/\"\n","                \"wsg_50_description/sdf/schunk_wsg_50_with_tip.sdf\"))\n","\n","    X_7G = RigidTransform(RollPitchYaw(np.pi / 2.0, 0, roll), [0, 0, 0.09])\n","    plant.WeldFrames(plant.GetFrameByName(\"iiwa_link_0_original\", iiwa_model_instance),\n","                     plant.GetFrameByName(\"body\", gripper), X_7G)\n","    return gripper"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import os\n","import sys\n","import warnings\n","\n","import numpy as np\n","from pydrake.all import (\n","    AbstractValue,\n","    Adder,\n","    AddMultibodyPlantSceneGraph,\n","    BallRpyJoint,\n","    BaseField,\n","    Box,\n","    CameraInfo,\n","    Capsule,\n","    ClippingRange,\n","    CoulombFriction,\n","    Cylinder,\n","    Demultiplexer,\n","    DepthImageToPointCloud,\n","    DepthRange,\n","    DepthRenderCamera,\n","    DiagramBuilder,\n","    DifferentialInverseKinematicsIntegrator,\n","    DifferentialInverseKinematicsParameters,\n","    GeometryInstance,\n","    InverseDynamicsController,\n","    LeafSystem,\n","    MakeMultibodyStateToWsgStateSystem,\n","    MakePhongIllustrationProperties,\n","    MakeRenderEngineVtk,\n","    ModelInstanceIndex,\n","    MultibodyPlant,\n","    Parser,\n","    PassThrough,\n","    PrismaticJoint,\n","    RenderCameraCore,\n","    RenderEngineVtkParams,\n","    RevoluteJoint,\n","    Rgba,\n","    RgbdSensor,\n","    RigidTransform,\n","    RollPitchYaw,\n","    RotationMatrix,\n","    SchunkWsgPositionController,\n","    SpatialInertia,\n","    Sphere,\n","    StateInterpolatorWithDiscreteDerivative,\n","    UnitInertia,\n",")\n","\n"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["\n","\n","def CustomAddRgbdSensors(\n","    builder,\n","    plant,\n","    scene_graph,\n","    also_add_point_clouds=True,\n","    model_instance_prefix=\"camera\",\n","    depth_camera=None,\n","    renderer=None,\n","):\n","    \n","    \"\"\"\n","    Adds a RgbdSensor to the first body in the plant for every model instance\n","    with a name starting with model_instance_prefix.  If depth_camera is None,\n","    then a default camera info will be used.  If renderer is None, then we will\n","    assume the name 'my_renderer', and create a VTK renderer if a renderer of\n","    that name doesn't exist.\n","    \"\"\"\n","    if sys.platform == \"linux\" and os.getenv(\"DISPLAY\") is None:\n","        from pyvirtualdisplay import Display\n","\n","        virtual_display = Display(visible=0, size=(1400, 900))\n","        virtual_display.start()\n","\n","    if not renderer:\n","        renderer = \"my_renderer\"\n","\n","    if not scene_graph.HasRenderer(renderer):\n","        scene_graph.AddRenderer(\n","            renderer, MakeRenderEngineVtk(RenderEngineVtkParams())\n","        )\n","\n","    if not depth_camera:\n","        depth_camera = DepthRenderCamera(\n","            RenderCameraCore(\n","                renderer,\n","                CameraInfo(width=640, height=480, fov_y=np.pi / 4.0),\n","                ClippingRange(near=0.1, far=10.0),\n","                RigidTransform(),\n","            ),\n","            DepthRange(0.1, 10.0),\n","        )\n","\n","    for index in range(plant.num_model_instances()):\n","        model_instance_index = ModelInstanceIndex(index)\n","        model_name = plant.GetModelInstanceName(model_instance_index)\n","\n","        if model_name.startswith(model_instance_prefix):\n","            body_index = plant.GetBodyIndices(model_instance_index)[0]\n","            rgbd = builder.AddSystem(\n","                RgbdSensor(\n","                    parent_id=plant.GetBodyFrameIdOrThrow(body_index),\n","                    X_PB=RigidTransform(),\n","                    depth_camera=depth_camera,\n","                    show_window=False,\n","                )\n","            )\n","            rgbd.set_name(model_name)\n","            builder.Connect(\n","                scene_graph.get_query_output_port(),\n","                rgbd.query_object_input_port(),\n","            )\n","\n","            # Export the camera outputs\n","            builder.ExportOutput(\n","                rgbd.color_image_output_port(), f\"{model_name}_rgb_image\"\n","            )\n","            builder.ExportOutput(\n","                rgbd.depth_image_32F_output_port(), f\"{model_name}_depth_image\"\n","            )\n","            builder.ExportOutput(\n","                rgbd.label_image_output_port(), f\"{model_name}_label_image\"\n","            )\n","\n","            if also_add_point_clouds:\n","                # Add a system to convert the camera output into a point cloud\n","                to_point_cloud = builder.AddSystem(\n","                    DepthImageToPointCloud(\n","                        camera_info=rgbd.depth_camera_info(),\n","                        fields=BaseField.kXYZs | BaseField.kRGBs,\n","                    )\n","                )\n","                builder.Connect(\n","                    rgbd.depth_image_32F_output_port(),\n","                    to_point_cloud.depth_image_input_port(),\n","                )\n","                builder.Connect(\n","                    rgbd.color_image_output_port(),\n","                    to_point_cloud.color_image_input_port(),\n","                )\n","\n","                class ExtractBodyPose(LeafSystem):\n","                    def __init__(self, body_index):\n","                        LeafSystem.__init__(self)\n","                        self.body_index = body_index\n","                        self.DeclareAbstractInputPort(\n","                            \"poses\",\n","                            plant.get_body_poses_output_port().Allocate(),\n","                        )\n","                        self.DeclareAbstractOutputPort(\n","                            \"pose\",\n","                            lambda: AbstractValue.Make(RigidTransform()),\n","                            self.CalcOutput,\n","                        )\n","\n","                    def CalcOutput(self, context, output):\n","                        poses = self.EvalAbstractInput(context, 0).get_value()\n","                        pose = poses[int(self.body_index)]\n","                        output.get_mutable_value().set(\n","                            pose.rotation(), pose.translation()\n","                        )\n","\n","                camera_pose = builder.AddSystem(ExtractBodyPose(body_index))\n","                builder.Connect(\n","                    plant.get_body_poses_output_port(),\n","                    camera_pose.get_input_port(),\n","                )\n","                builder.Connect(\n","                    camera_pose.get_output_port(),\n","                    to_point_cloud.GetInputPort(\"camera_pose\"),\n","                )\n","\n","                # Export the point cloud output.\n","                builder.ExportOutput(\n","                    to_point_cloud.point_cloud_output_port(),\n","                    f\"{model_name}_point_cloud\",\n","                )\n","\n","                # ----------------------------------------------------------------\n","                mask_system = builder.AddSystem(MaskSystem(rgbd))\n","                \n","                builder.Connect(rgbd.color_image_output_port(),\n","                                mask_system.get_input_port(0))\n","                builder.Connect(rgbd.depth_image_32F_output_port(),\n","                    mask_system.GetInputPort('depth_image'))\n","                builder.ExportOutput(mask_system.GetOutputPort('masked_depth_image'),\n","                    f\"{model_name}_masked_depth_image\")\n","                \n","                pcds = builder.AddSystem(CreatePointClouds(rgbd))\n","                builder.Connect(mask_system.GetOutputPort('masked_depth_image'),\n","                    pcds.GetInputPort('depth_image_stack'))\n","                builder.Connect(rgbd.body_pose_in_world_output_port(),\n","                    pcds.GetInputPort('rgbd_sensor_body_pose'))\n","                builder.ExportOutput(pcds.GetOutputPort('pcd_stack'),\n","                    f\"{model_name}_pcd_stack\")\n","\n","\n","                "]},{"cell_type":"code","execution_count":23,"metadata":{"cell_id":"ade44bfca6b74478bc20d4ccf0e6b051","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":4,"execution_start":1682523014450,"is_code_hidden":true,"source_hash":"9807b08a"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-11 22:03:32.763626 \n"]}],"source":["def CustomMakeManipulationStation(model_directives=None,\n","                            filename=None,\n","                            time_step=0.002,\n","                            iiwa_prefix=\"iiwa\",\n","                            wsg_prefix=\"wsg\",\n","                            camera_prefix=\"camera\",\n","                            prefinalize_callback=None,\n","                            package_xmls=[]):\n","    \"\"\"\n","\n","    \"\"\"\n","    builder = DiagramBuilder()\n","    # asdsadsadsdasdasdas\n","    # Add (only) the iiwa, WSG, and cameras to the scene.\n","    plant, scene_graph = AddMultibodyPlantSceneGraph(builder,\n","                                                     time_step=time_step)\n","    parser = Parser(plant)\n","    for p in package_xmls:\n","        parser.package_map().AddPackageXml(p)\n","    AddPackagePaths(parser)\n","    if model_directives:\n","        directives = LoadModelDirectivesFromString(model_directives)\n","        ProcessModelDirectives(directives, parser)\n","    if filename:\n","        parser.AddAllModelsFromFile(filename)\n","    if prefinalize_callback:\n","        prefinalize_callback(plant)\n","    plant.Finalize()\n","\n","    for i in range(plant.num_model_instances()):\n","        model_instance = ModelInstanceIndex(i)\n","        model_instance_name = plant.GetModelInstanceName(model_instance)\n","\n","        if model_instance_name.startswith(iiwa_prefix):\n","            print(\"adding iiwa \", model_instance_name)\n","            num_iiwa_positions = plant.num_positions(model_instance)\n","            print(model_instance_name, \" num_iiwa_positions:\",num_iiwa_positions)\n","            # I need a PassThrough system so that I can export the input port.\n","            iiwa_position = builder.AddSystem(PassThrough(num_iiwa_positions))\n","            builder.ExportInput(iiwa_position.get_input_port(),\n","                                model_instance_name + \"_position\")\n","            builder.ExportOutput(iiwa_position.get_output_port(),\n","                                 model_instance_name + \"_position_commanded\")\n","\n","            # Export the iiwa \"state\" outputs.\n","            demux = builder.AddSystem(\n","                Demultiplexer(2 * num_iiwa_positions, num_iiwa_positions))\n","            print('size: ',plant.get_state_output_port(model_instance).size(), ' ',\n","                            demux.get_input_port().size())\n","            \n","            print('size: ',demux.get_output_port(0).size(), ' ',\n","                            demux.get_output_port(1).size())\n","\n","            \n","\n","            builder.Connect(plant.get_state_output_port(model_instance),\n","                            demux.get_input_port())\n","            builder.ExportOutput(demux.get_output_port(0),\n","                                 model_instance_name + \"_position_measured\")\n","            builder.ExportOutput(demux.get_output_port(1),\n","                                 model_instance_name + \"_velocity_estimated\")\n","            builder.ExportOutput(plant.get_state_output_port(model_instance),\n","                                 model_instance_name + \"_state_estimated\")\n","\n","            # Make the plant for the iiwa controller to use.\n","            controller_plant = MultibodyPlant(time_step=time_step)\n","            # # TODO: Add the correct IIWA model (introspected from MBP)\n","            # if plant.num_positions(model_instance) == 3:\n","            #     controller_iiwa = AddPlanarIiwa(controller_plant)\n","            # else:\n","            # controller_iiwa = AddIiwa(controller_plant)\n","            sdf_path = FindResourceOrThrow(\n","                \"drake/manipulation/models/iiwa_description/iiwa7/\"\n","                f\"iiwa7_no_collision.sdf\")\n","\n","            # AddIiwa {\n","            \n","            parser = Parser(controller_plant)\n","            \n","            \n","            controller_iiwa = parser.AddModelFromFile(\"iiwa_description/iiwa7/iiwa7_with_box_collision.sdf\")\n","            # controller_iiwa = parser.AddModelFromFile(\"iiwa_description/iiwa7/iiwa7_no_collision.sdf\")\n","            \n","            #  controller_iiwa = parser.AddModelFromFile(\"package://drake/manipulation/models/iiwa_description/iiwa7/iiwa7_no_collision.sdf\") \n","            # controller_iiwa = parser.AddModelFromFile(sdf_path)\n","\n","            controller_plant.WeldFrames(controller_plant.world_frame(), controller_plant.GetFrameByName(\"iiwa_link_0\"))\n","            # freebox_body_x = controller_plant.AddRigidBody(\n","            #         \"freebox_body_x\", iiwa,\n","            #         SpatialInertia(0, [0, 0, 0], UnitInertia(0, 0, 0)))\n","\n","            # freebox_joint_x = controller_plant.AddJoint(PrismaticJoint(\n","            #         \"freebox_joint_x\", controller_plant.world_frame(), controller_plant.GetFrameByName(\"iiwa_link_0_x\"), \n","            #         [1, 0, 0]))\n","            # plant.AddJointActuator(\"freebox_joint_x_actuator\", freebox_joint_x)\n","        \n","            # Set default positions:\n","            q0 = [0, 0, 0, 0.0, 0.1, 0, -1.2, 0, 1.6, 0]\n","            index = 0\n","            for joint_index in controller_plant.GetJointIndices(controller_iiwa):\n","                joint = controller_plant.get_mutable_joint(joint_index)\n","                if isinstance(joint, RevoluteJoint):\n","                    joint.set_default_angle(q0[index])\n","                    index += 1\n","                if isinstance(joint, PrismaticJoint):\n","                    joint.set_default_translation(q0[index])\n","                    index += 1\n","                \n","            # } AddIiwa\n","            #add_freebox(controller_plant) \n","                \n","\n","            AddWsg(controller_plant, controller_iiwa, welded=True)\n","            controller_plant.Finalize()\n","\n","            kp=np.array([100] * num_iiwa_positions)\n","            print(\"num_iiwa_positions \", num_iiwa_positions)\n","            print(\"dim=kp.size() \", kp.size)\n","            print(\"controller_plant.num_positions \", controller_plant.num_positions())\n","            print(\"controller_plant.num_velocities \", controller_plant.num_velocities())\n","            print(\"controller_plant.num_actuators \", controller_plant.num_actuators())\n","            # Add the iiwa controller\n","            iiwa_controller = builder.AddSystem(\n","                InverseDynamicsController(controller_plant,\n","                                          kp=[100] * num_iiwa_positions,\n","                                          ki=[1] * num_iiwa_positions,\n","                                          kd=[20] * num_iiwa_positions,\n","                                          has_reference_acceleration=False))\n","            iiwa_controller.set_name(model_instance_name + \"_controller\")\n","            builder.Connect(plant.get_state_output_port(model_instance),\n","                            iiwa_controller.get_input_port_estimated_state())\n","\n","            # Add in the feed-forward torque\n","            adder = builder.AddSystem(Adder(2, num_iiwa_positions))\n","            builder.Connect(iiwa_controller.get_output_port_control(),\n","                            adder.get_input_port(0))\n","            # Use a PassThrough to make the port optional (it will provide zero\n","            # values if not connected).\n","            torque_passthrough = builder.AddSystem(\n","                PassThrough([0] * num_iiwa_positions))\n","            builder.Connect(torque_passthrough.get_output_port(),\n","                            adder.get_input_port(1))\n","            builder.ExportInput(torque_passthrough.get_input_port(),\n","                                model_instance_name + \"_feedforward_torque\")\n","            builder.Connect(adder.get_output_port(),\n","                            plant.get_actuation_input_port(model_instance))\n","\n","            # Add discrete derivative to command velocities.\n","            desired_state_from_position = builder.AddSystem(\n","                StateInterpolatorWithDiscreteDerivative(\n","                    num_iiwa_positions,\n","                    time_step,\n","                    suppress_initial_transient=True))\n","            desired_state_from_position.set_name(\n","                model_instance_name + \"_desired_state_from_position\")\n","            builder.Connect(desired_state_from_position.get_output_port(),\n","                            iiwa_controller.get_input_port_desired_state())\n","            builder.Connect(iiwa_position.get_output_port(),\n","                            desired_state_from_position.get_input_port())\n","\n","            # Export commanded torques.\n","            builder.ExportOutput(adder.get_output_port(),\n","                                 model_instance_name + \"_torque_commanded\")\n","            builder.ExportOutput(adder.get_output_port(),\n","                                 model_instance_name + \"_torque_measured\")\n","\n","            builder.ExportOutput(\n","                plant.get_generalized_contact_forces_output_port(\n","                    model_instance), model_instance_name + \"_torque_external\")\n","        \n","        \n","        elif model_instance_name == \"storage\":\n","            print(\"adding storage\")\n","            num_iiwa_positions = plant.num_positions(model_instance)\n","            print(model_instance_name, \" num_iiwa_positions:\", num_iiwa_positions)\n","            # I need a PassThrough system so that I can export the input port.\n","            iiwa_position = builder.AddSystem(PassThrough(num_iiwa_positions))\n","            builder.ExportInput(iiwa_position.get_input_port(),\n","                                model_instance_name + \"_position\")\n","            builder.ExportOutput(iiwa_position.get_output_port(),\n","                                 model_instance_name + \"_position_commanded\")\n","\n","            # Export the iiwa \"state\" outputs.\n","            demux = builder.AddSystem(\n","                Demultiplexer(2 * num_iiwa_positions, num_iiwa_positions))\n","            print('size: ',plant.get_state_output_port(model_instance).size(), ' ',\n","                            demux.get_input_port().size())\n","            \n","            print('size: ',demux.get_output_port(0).size(), ' ',\n","                            demux.get_output_port(1).size())\n","\n","            \n","\n","            builder.Connect(plant.get_state_output_port(model_instance),\n","                            demux.get_input_port())\n","            builder.ExportOutput(demux.get_output_port(0),\n","                                 model_instance_name + \"_position_measured\")\n","            builder.ExportOutput(demux.get_output_port(1),\n","                                 model_instance_name + \"_velocity_estimated\")\n","            builder.ExportOutput(plant.get_state_output_port(model_instance),\n","                                 model_instance_name + \"_state_estimated\")\n","\n","            # Make the plant for the iiwa controller to use.\n","            controller_plant = MultibodyPlant(time_step=time_step)\n","            # # TODO: Add the correct IIWA model (introspected from MBP)\n","            # if plant.num_positions(model_instance) == 3:\n","            #     controller_iiwa = AddPlanarIiwa(controller_plant)\n","            # else:\n","            # controller_iiwa = AddIiwa(controller_plant)\n","\n","            # AddIiwa {\n","            \n","            parser = Parser(controller_plant)\n","            \n","            \n","            controller_iiwa = parser.AddModelFromFile(\"iiwa_description/iiwa7/storage.sdf\")\n","            # controller_iiwa = parser.AddModelFromFile(\"iiwa_description/iiwa7/iiwa7_no_collision.sdf\")\n","            \n","            #  controller_iiwa = parser.AddModelFromFile(\"package://drake/manipulation/models/iiwa_description/iiwa7/iiwa7_no_collision.sdf\") \n","            # controller_iiwa = parser.AddModelFromFile(sdf_path)\n","\n","            controller_plant.WeldFrames(controller_plant.world_frame(), controller_plant.GetFrameByName(\"iiwa_link_0\"))\n","            # freebox_body_x = controller_plant.AddRigidBody(\n","            #         \"freebox_body_x\", iiwa,\n","            #         SpatialInertia(0, [0, 0, 0], UnitInertia(0, 0, 0)))\n","\n","            # freebox_joint_x = controller_plant.AddJoint(PrismaticJoint(\n","            #         \"freebox_joint_x\", controller_plant.world_frame(), controller_plant.GetFrameByName(\"iiwa_link_0_x\"), \n","            #         [1, 0, 0]))\n","            # plant.AddJointActuator(\"freebox_joint_x_actuator\", freebox_joint_x)\n","        \n","            # Set default positions:\n","            q0 = [5.0, 0.0, 0.0]\n","            index = 0\n","            for joint_index in controller_plant.GetJointIndices(controller_iiwa):\n","                joint = controller_plant.get_mutable_joint(joint_index)\n","                if isinstance(joint, RevoluteJoint):\n","                    joint.set_default_angle(q0[index])\n","                    index += 1\n","                if isinstance(joint, PrismaticJoint):\n","                    joint.set_default_translation(q0[index])\n","                    index += 1\n","                \n","            # } AddIiwa\n","            #add_freebox(controller_plant) \n","                \n","\n","            CustomAddWsg(controller_plant, controller_iiwa, welded=True)\n","            controller_plant.Finalize()\n","\n","            kp=np.array([100] * num_iiwa_positions)\n","            print(\"num_iiwa_positions \", num_iiwa_positions)\n","            print(\"dim=kp.size() \", kp.size)\n","            print(\"controller_plant.num_positions \", controller_plant.num_positions())\n","            print(\"controller_plant.num_velocities \", controller_plant.num_velocities())\n","            print(\"controller_plant.num_actuators \", controller_plant.num_actuators())\n","            \n","            # Add the iiwa controller\n","            iiwa_controller = builder.AddSystem(\n","                InverseDynamicsController(controller_plant,\n","                                          kp=[100] * num_iiwa_positions,\n","                                          ki=[1] * num_iiwa_positions,\n","                                          kd=[20] * num_iiwa_positions,\n","                                          has_reference_acceleration=False))\n","            iiwa_controller.set_name(model_instance_name + \"_controller\")\n","            builder.Connect(plant.get_state_output_port(model_instance),\n","                            iiwa_controller.get_input_port_estimated_state())\n","\n","            # Add in the feed-forward torque\n","            adder = builder.AddSystem(Adder(2, num_iiwa_positions))\n","            builder.Connect(iiwa_controller.get_output_port_control(),\n","                            adder.get_input_port(0))\n","            # Use a PassThrough to make the port optional (it will provide zero\n","            # values if not connected).\n","            torque_passthrough = builder.AddSystem(\n","                PassThrough([0] * num_iiwa_positions))\n","            builder.Connect(torque_passthrough.get_output_port(),\n","                            adder.get_input_port(1))\n","            builder.ExportInput(torque_passthrough.get_input_port(),\n","                                model_instance_name + \"_feedforward_torque\")\n","            builder.Connect(adder.get_output_port(),\n","                            plant.get_actuation_input_port(model_instance))\n","\n","            # Add discrete derivative to command velocities.\n","            desired_state_from_position = builder.AddSystem(\n","                StateInterpolatorWithDiscreteDerivative(\n","                    num_iiwa_positions,\n","                    time_step,\n","                    suppress_initial_transient=True))\n","            desired_state_from_position.set_name(\n","                model_instance_name + \"_desired_state_from_position\")\n","            builder.Connect(desired_state_from_position.get_output_port(),\n","                            iiwa_controller.get_input_port_desired_state())\n","            builder.Connect(iiwa_position.get_output_port(),\n","                            desired_state_from_position.get_input_port())\n","\n","            # Export commanded torques.\n","            builder.ExportOutput(adder.get_output_port(),\n","                                 model_instance_name + \"_torque_commanded\")\n","            builder.ExportOutput(adder.get_output_port(),\n","                                 model_instance_name + \"_torque_measured\")\n","\n","            builder.ExportOutput(\n","                plant.get_generalized_contact_forces_output_port(\n","                    model_instance), model_instance_name + \"_torque_external\")\n","        elif model_instance_name.startswith(wsg_prefix):\n","\n","            # Wsg controller.\n","            wsg_controller = builder.AddSystem(SchunkWsgPositionController())\n","            wsg_controller.set_name(model_instance_name + \"_controller\")\n","            builder.Connect(wsg_controller.get_generalized_force_output_port(),\n","                            plant.get_actuation_input_port(model_instance))\n","            builder.Connect(plant.get_state_output_port(model_instance),\n","                            wsg_controller.get_state_input_port())\n","            builder.ExportInput(\n","                wsg_controller.get_desired_position_input_port(),\n","                model_instance_name + \"_position\")\n","            builder.ExportInput(wsg_controller.get_force_limit_input_port(),\n","                                model_instance_name + \"_force_limit\")\n","            wsg_mbp_state_to_wsg_state = builder.AddSystem(\n","                MakeMultibodyStateToWsgStateSystem())\n","            builder.Connect(plant.get_state_output_port(model_instance),\n","                            wsg_mbp_state_to_wsg_state.get_input_port())\n","            builder.ExportOutput(wsg_mbp_state_to_wsg_state.get_output_port(),\n","                                 model_instance_name + \"_state_measured\")\n","            builder.ExportOutput(wsg_controller.get_grip_force_output_port(),\n","                                 model_instance_name + \"_force_measured\")\n","\n","\n","    # Cameras.\n","    CustomAddRgbdSensors(builder,\n","                   plant,\n","                   scene_graph,\n","                   model_instance_prefix=camera_prefix)\n","\n","    # Export \"cheat\" ports.\n","    builder.ExportOutput(scene_graph.get_query_output_port(), \"query_object\")\n","    builder.ExportOutput(plant.get_contact_results_output_port(),\n","                         \"contact_results\")\n","    builder.ExportOutput(plant.get_state_output_port(),\n","                         \"plant_continuous_state\")\n","    builder.ExportOutput(plant.get_body_poses_output_port(), \"body_poses\")\n","\n","    diagram = builder.Build()\n","    diagram.set_name(\"ManipulationStation\")\n","    return diagram\n","\n","saat()"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["params = 0\n","\n","def CustomAddIiwaDifferentialIK(builder, plant, frame=None, n=0):\n","    global params\n","    params = DifferentialInverseKinematicsParameters(plant.num_positions(),\n","                                                     plant.num_velocities())\n","    time_step = plant.time_step()\n","    q0 = plant.GetPositions(plant.CreateDefaultContext())\n","    params.set_nominal_joint_position(q0)\n","    params.set_end_effector_angular_speed_limit(2)\n","    # params.set_end_effector_translational_velocity_limits([-2, -2, -2],\n","    #                                                       [2, 2, 2])\n","    if plant.num_positions() == 3:  # planar iiwa\n","        frame = plant.GetFrameByName(\"iiwa_link_0_z\")\n","        iiwa14_velocity_limits = np.array([1.4, 1.3, 2.3])\n","        params.set_joint_velocity_limits(\n","            (-iiwa14_velocity_limits, iiwa14_velocity_limits))\n","        # These constants are in body frame\n","        # assert (\n","        #     frame.name() == \"iiwa_link_7\"\n","        # ), \"Still need to generalize the remaining planar diff IK params for different frames\"  # noqa\n","        # params.set_end_effector_velocity_flag(\n","        #     [True, False, False, True, False, True])\n","    else:\n","        iiwa14_velocity_limits = np.array([0.5, 0.5, 0.5, 1.4, 1.4, 1.7, 1.3, 2.2, 2.3, 2.3])\n","        params.set_joint_velocity_limits(\n","            (-iiwa14_velocity_limits, iiwa14_velocity_limits))\n","        \n","        # matrix = 50 * np.eye(10)\n","\n","        # for i in range(3):\n","        #     for k in range(10):\n","        #         matrix[i, k] = 0.1  \n","        # params.set_joint_centering_gain(matrix)\n","\n","        \n","    if frame is None:\n","        frame = plant.GetFrameByName(\"body\")\n","\n","    print(\"frame\", frame)\n","    differential_ik = builder.AddSystem(\n","        DifferentialInverseKinematicsIntegrator(\n","            plant,\n","            frame,\n","            time_step,\n","            params,\n","            log_only_when_result_state_changes=True))\n","    \n","    return differential_ik"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["# Takes 3 point clouds (in world coordinates) as input, and outputs and estimated pose for the mustard bottle.\n","\n","class MustardIterativeClosestPoint(LeafSystem):\n","    \n","    def __init__(self):\n","        LeafSystem.__init__(self)\n","        model_point_cloud = AbstractValue.Make(PointCloud(0))\n","        self.DeclareAbstractInputPort(\"cloud0\", model_point_cloud)\n","        self.DeclareAbstractInputPort(\"cloud1\", model_point_cloud)\n","        self.DeclareAbstractInputPort(\"cloud2\", model_point_cloud)\n","        self.inputs = []\n","\n","\n","        img1 = AbstractValue.Make(ImageRgba8U(480, 640, 0))\n","        depth1 = AbstractValue.Make(ImageDepth32F(480, 640, .0))\n","\n","        self.DeclareAbstractInputPort(\"image0\", img1)\n","        self.DeclareAbstractInputPort(\"depth0\", depth1)\n","\n","\n","        self.DeclareAbstractInputPort(\"image1\", img1)\n","        self.DeclareAbstractInputPort(\"depth1\", depth1)\n","\n","        self.DeclareAbstractInputPort(\"image2\", img1)\n","        self.DeclareAbstractInputPort(\"depth2\", depth1)\n","\n","\n","        # deneme amacli port\n","        # self.DeclareAbstractInputPort(\"cloud3\", AbstractValue.Make([np.ndarray]))\n","        self.DeclareAbstractInputPort(\"cloud4\", AbstractValue.Make([np.ndarray]))\n","        \n","\n","        self.DeclareAbstractOutputPort(\n","            \"X_WO\", lambda: AbstractValue.Make(RigidTransform()),\n","            self.EstimatePose)\n","\n","        self.mustard = CrackerBoxPointCloud.CrackerBoxPointCloud()\n","        meshcat.SetObject(\"icp_scene\", self.mustard)\n","        meshcat.SetObject(\"icp_model\", self.mustard)\n","\n","\n","    def EstimatePose(self, context, output):\n","        pcd = []\n","        print(\"EstimatePose\")\n","        #global inputs\n","        for i in range(10):\n","            print(\"İnputs : i\", i)\n","            #inputs[i] = (self.get_input_port(i).Eval(context))\n","\n","            self.inputs.append(self.get_input_port(i).Eval(context))\n","            print(self.inputs[i])\n","\n","\n","        # for i in (3, 5, 7):\n","            # print input clouds\n","            # print(\"cloud\", i, cloud.xyzs())\n","\n","            # plot point clouds\n","\n","            '''\n","            # TODO: create image from xyzs\n","            # # Plot the two images.\n","            # plt.subplot(121)\n","            # plt.imshow(cloud)\n","            plt.title('cloud', i)\n","            # plt.subplot(122)\n","            plt.imshow(np.squeeze(self.inputs[i].data))\n","            plt.title('Depth image')\n","            # #mpld3.display()\n","            # plt.show()\n","            '''\n","\n","#                 cloud.Crop(lower_xyz=[-0.5, -1, 0.5], upper_xyz=[0.8, 0.8, 0.8]))\n","#                 cloud.Crop(lower_xyz=[-0.5, -0.87, 0.5], upper_xyz=[0.8, 0.8, 0.6]))\n","#               cloud.Crop(lower_xyz=[-0.5, -0.87, 0.4455], upper_xyz=[0.8, 0.8, 0.6]))\n","        # for i in range(3):\n","        #     pcd.append(\n","        #         #cloud.Crop(lower_xyz=[.4, -.2, 0.001], upper_xyz=[.6, .3, .3]))\n","        #         #\n","        #         # cloud.Crop(lower_xyz=[-0.11, -0.96, 0.43], upper_xyz=[-0., -0.94, 0.46]))\n","        #         #cloud.Crop(lower_xyz=[-0.5, -0.87, 0.2], upper_xyz=[0.8, 0.8, 0.6]))\n","        #         #cloud.Crop(lower_xyz=[-0.5, -0.87, 0.45], upper_xyz=[0.1, -0.86, 0.6]))\n","        #         self.inputs[i].Crop(lower_xyz=[-0.17, -1.07, -2], upper_xyz=[0, 0, 0.6]))\n","\n","        for i in range(len(self.inputs[9][0])):\n","            pcd.append(self.inputs[9][0][i])\n","\n","        # pcd.append(self.inputs[9][0][0])\n","        \n","        merged_pcd = Concatenate(pcd)\n","        down_sampled_pcd = merged_pcd.VoxelizedDownSample(voxel_size=0.005)\n","        meshcat.SetObject(\"icp_observations\",\n","                          down_sampled_pcd,\n","                          point_size=0.001)\n","\n","        # takes icp_observations + model cloud , returns icp?s\n","        X_WOhat, chat = IterativeClosestPoint(\n","            self.mustard.xyzs(),\n","            down_sampled_pcd.xyzs(),\n","            meshcat=meshcat,\n","            meshcat_scene_path=\"icp_scene\")\n","        print(\"X_WOhat = {}\".format(X_WOhat))\n","        output.set_value(X_WOhat)"]},{"cell_type":"code","execution_count":26,"metadata":{"cell_id":"6d8593093dfe4ae59d6325dfc8cef910","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":32979,"execution_start":1682523014488,"output_cleared":false,"source_hash":"a03c343d"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-05-11 22:03:32.971870 before def icp\n","frame <BodyFrame_[float] name='iiwa_link_0_z' index=41 model_instance=4>\n","model instance ModelInstanceIndex(4)\n","frame <BodyFrame_[float] name='storage_bottom_0_0' index=72 model_instance=14>\n","rigid transform RigidTransform(\n","  R=RotationMatrix([\n","    [1.0, 0.0, 0.0],\n","    [0.0, 1.0, 0.0],\n","    [0.0, 0.0, 1.0],\n","  ]),\n","  p=[-0.22499999999999998, 0.10800000000000001, 0.0],\n",")\n","frame <BodyFrame_[float] name='iiwa_link_0_z' index=41 model_instance=4>\n","model instance ModelInstanceIndex(4)\n","frame <BodyFrame_[float] name='storage_bottom_0_1' index=77 model_instance=19>\n","rigid transform RigidTransform(\n","  R=RotationMatrix([\n","    [1.0, 0.0, 0.0],\n","    [0.0, 1.0, 0.0],\n","    [0.0, 0.0, 1.0],\n","  ]),\n","  p=[-0.22499999999999998, -0.0, 0.0],\n",")\n","frame <BodyFrame_[float] name='iiwa_link_0_z' index=41 model_instance=4>\n","model instance ModelInstanceIndex(4)\n","frame <BodyFrame_[float] name='storage_bottom_1_0' index=82 model_instance=24>\n","rigid transform RigidTransform(\n","  R=RotationMatrix([\n","    [1.0, 0.0, 0.0],\n","    [0.0, 1.0, 0.0],\n","    [0.0, 0.0, 1.0],\n","  ]),\n","  p=[-0.383, 0.10800000000000001, 0.0],\n",")\n","frame <BodyFrame_[float] name='iiwa_link_0_z' index=41 model_instance=4>\n","model instance ModelInstanceIndex(4)\n","frame <BodyFrame_[float] name='storage_bottom_1_1' index=87 model_instance=29>\n","rigid transform RigidTransform(\n","  R=RotationMatrix([\n","    [1.0, 0.0, 0.0],\n","    [0.0, 1.0, 0.0],\n","    [0.0, 0.0, 1.0],\n","  ]),\n","  p=[-0.383, -0.0, 0.0],\n",")\n","adding iiwa  iiwa\n","iiwa  num_iiwa_positions: 10\n","size:  20   20\n","size:  10   10\n","num_iiwa_positions  10\n","dim=kp.size()  10\n","controller_plant.num_positions  10\n","controller_plant.num_velocities  10\n","controller_plant.num_actuators  10\n","adding storage\n","storage  num_iiwa_positions: 3\n","size:  6   6\n","size:  3   3\n","num_iiwa_positions  3\n","dim=kp.size()  3\n","controller_plant.num_positions  3\n","controller_plant.num_velocities  3\n","controller_plant.num_actuators  3\n","after add station\n","camera3_origin, <FixedOffsetFrame_[float] name='camera3_origin' index=62 model_instance=0>\n","camera4_origin, <FixedOffsetFrame_[float] name='camera4_origin' index=65 model_instance=0>\n","camera5_origin, <FixedOffsetFrame_[float] name='camera5_origin' index=68 model_instance=0>\n","frame <BodyFrame_[float] name='body' index=30 model_instance=3>\n","frame <BodyFrame_[float] name='iiwa_link_0_z' index=3 model_instance=2>\n","EstimatePose\n","İnputs : i 0\n","<pydrake.perception.PointCloud object at 0x7f800f788bb0>\n","İnputs : i 1\n","<pydrake.perception.PointCloud object at 0x7f800f788cf0>\n","İnputs : i 2\n","<pydrake.perception.PointCloud object at 0x7f800f79d870>\n","İnputs : i 3\n","<pydrake.systems.sensors.Image[PixelType.kRgba8U] object at 0x7f800ef4a0f0>\n","İnputs : i 4\n","<pydrake.systems.sensors.Image[PixelType.kDepth32F] object at 0x7f800ef4a0b0>\n","İnputs : i 5\n","<pydrake.systems.sensors.Image[PixelType.kRgba8U] object at 0x7f803c868bb0>\n","İnputs : i 6\n","<pydrake.systems.sensors.Image[PixelType.kDepth32F] object at 0x7f800ef4a670>\n","İnputs : i 7\n","<pydrake.systems.sensors.Image[PixelType.kRgba8U] object at 0x7f800ef4aaf0>\n","İnputs : i 8\n","<pydrake.systems.sensors.Image[PixelType.kDepth32F] object at 0x7f800ef4a4b0>\n","İnputs : i 9\n","before pcikle\n","after save\n","after pickle\n","4915 1944\n"]},{"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'width'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-f26d62a99f84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;31m# print(\"camera3_pcd_stack\", station.GetOutputPort('camera3_pcd_stack').Eval(station.GetSubsystemByName(\"CreatePointclouds\").GetMyContextFromRoot(context)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m \u001b[0msimulator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m#color_image = station.GetOutputPort(\"camera3_point_cloud\").Eval(context)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-17-9c5015635638>\u001b[0m in \u001b[0;36mPlan\u001b[0;34m(self, context, state)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mX_O\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_port\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# X_O[i][\"initial\"]= RigidTransform(RotationMatrix.MakeXRotation(np.pi), [1.0, 0.0, 0.500])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-25-d0fbb61fdd03>\u001b[0m in \u001b[0;36mEstimatePose\u001b[0;34m(self, context, output)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;31m#inputs[i] = (self.get_input_port(i).Eval(context))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_port\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-21742309ed0d>\u001b[0m in \u001b[0;36mcalc_output\u001b[0;34m(self, context, output)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mX_WC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetInputPort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rgbd_sensor_body_pose'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mdepth_image_stack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpieces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetInputPort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'depth_image_stack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mpcds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdepth_image_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-44fba5a64ce0>\u001b[0m in \u001b[0;36mget_masks\u001b[0;34m(self, context, output)\u001b[0m\n\u001b[1;32m    147\u001b[0m                 \u001b[0;31m# if res3 is greater than res4 and res5, then the object is red\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0;31m# if ( res3 > res4 and res3 > res5):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolorFilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m                     \u001b[0;31m# print(\"red is detected\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m                     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-44fba5a64ce0>\u001b[0m in \u001b[0;36mcolorFilter\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Loop through each pixel in the image and count the number of pixels that are close to red\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mred_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mtotal_pixels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'width'"]}],"source":["saat(\"before def icp\" )\n","# def icp_pick_and_place_demo():\n","builder = DiagramBuilder()\n","\n","station = builder.AddSystem(\n","    CustomMakeManipulationStation(model_directives, time_step=0.002, prefinalize_callback=setup))\n","print(\"after add station\")\n","\n","\n","\n","plant = station.GetSubsystemByName(\"plant\")\n","scene_graph = station.GetSubsystemByName(\"scene_graph\")\n","\n","# iiwa = plant.GetModelInstanceByName(\"iiwa2\")\n","# print(\"num pos iiwa2\",plant.num_positions(iiwa))\n","\n","\n","# Find camera frames\n","frames = []\n","for i in range(3):\n","    frames.append(plant.GetFrameByName(f\"camera{i+3}_origin\"))\n","    print(f\"camera{i+3}_origin, {frames[i]}\")\n","# for each frame add triads\n","# for i in range(1):\n","#     AddMultibodyTriad(frames[i], scene_graph, length=.1, radius=0.005)\n","\n","# Add meshcet triads for cameras\n","for i in range(3):\n","    AddMeshcatTriad(meshcat, f\"camera{i+3}_origin\", X_PT=frames[i].GetFixedPoseInBodyFrame())\n","\n","\n","\n","icp = builder.AddSystem((MustardIterativeClosestPoint()))\n","builder.Connect(station.GetOutputPort(\"camera3_point_cloud\"),\n","                icp.get_input_port(0))\n","builder.Connect(station.GetOutputPort(\"camera4_point_cloud\"),\n","                icp.get_input_port(1))\n","builder.Connect(station.GetOutputPort(\"camera5_point_cloud\"),\n","                icp.get_input_port(2))\n","\n","builder.Connect(station.GetOutputPort(\"camera3_rgb_image\"),\n","                icp.get_input_port(3))\n","builder.Connect(station.GetOutputPort(\"camera3_depth_image\"),\n","                icp.get_input_port(4))\n","builder.Connect(station.GetOutputPort(\"camera4_rgb_image\"),\n","                icp.get_input_port(5))\n","builder.Connect(station.GetOutputPort(\"camera4_depth_image\"),\n","                icp.get_input_port(6))\n","builder.Connect(station.GetOutputPort(\"camera5_rgb_image\"),\n","                icp.get_input_port(7))\n","builder.Connect(station.GetOutputPort(\"camera5_depth_image\"),\n","                icp.get_input_port(8))\n","# deneme\n","# builder.Connect(station.GetOutputPort(\"camera3_masked_depth_image\"),\n","#                 icp.get_input_port(9))\n","\n","builder.Connect(station.GetOutputPort(\"camera4_pcd_stack\"),\n","                icp.get_input_port(9))\n","\n","\n","plan = builder.AddSystem(PickAndPlaceTrajectory3(plant))\n","builder.Connect(station.GetOutputPort(\"body_poses\"),\n","                plan.GetInputPort(\"body_poses\"))\n","builder.Connect(icp.GetOutputPort(\"X_WO\"), plan.GetInputPort(\"X_WO\"))\n","\n","robot = station.GetSubsystemByName(\n","    \"iiwa_controller\").get_multibody_plant_for_control()\n","\n","# Set up differential inverse kinematics.\n","diff_ik = CustomAddIiwaDifferentialIK(builder, robot, None, 0)\n","builder.Connect(diff_ik.get_output_port(),\n","                station.GetInputPort(\"iiwa_position\"))\n","builder.Connect(plan.GetOutputPort(\"X_WG\"),\n","                diff_ik.get_input_port(0))\n","builder.Connect(station.GetOutputPort(\"iiwa_state_estimated\"),\n","                diff_ik.GetInputPort(\"robot_state\"))\n","\n","\n","builder.Connect(plan.GetOutputPort(\"wsg_position\"),\n","                station.GetInputPort(\"wsg_position\"))\n","# ---------------------------------\n","\n","robot2 = station.GetSubsystemByName(\n","\"storage_controller\").get_multibody_plant_for_control()\n","# ---------------------------------\n","# connect storage planner\n","storage_planner = builder.AddSystem(StoragePlanner(plant))\n","\n","builder.Connect(station.GetOutputPort(\"body_poses\"),\n","                storage_planner.GetInputPort(\"body_poses\"))\n","\n","diff_ik2 = CustomAddIiwaDifferentialIK(builder, robot2, None, 2)\n","builder.Connect(storage_planner.GetOutputPort(\"X_WG\"),\n","                diff_ik2.get_input_port(0))\n","\n","builder.Connect(station.GetOutputPort(\"storage_state_estimated\"),\n","                diff_ik2.GetInputPort(\"robot_state\"))\n","\n","builder.Connect(diff_ik2.get_output_port(),\n","                station.GetInputPort(\"storage_position\"))\n","\n","\n","\n","visualizer = MeshcatVisualizer.AddToBuilder(\n","    builder, station.GetOutputPort(\"query_object\"), meshcat)\n","\n","\n","global diagram\n","diagram = builder.Build()\n","\n","simulator = Simulator(diagram)\n","context = simulator.get_context()\n","# print(\"camera3_pcd_stack\", station.GetOutputPort('camera3_pcd_stack').Eval(station.GetSubsystemByName(\"CreatePointclouds\").GetMyContextFromRoot(context)))\n","\n","simulator.Initialize()\n","\n","#color_image = station.GetOutputPort(\"camera3_point_cloud\").Eval(context)\n","#depth_image = station.GetOutputPort(\"camera3_point_cloud\").Eval(context)\n","\n","# # Plot the two images.\n","#plt.subplot(121)\n","#plt.imshow(color_image.data)\n","#plt.title('Color image')\n","#plt.subplot(122)\n","#plt.imshow(np.squeeze(depth_image.data))\n","#plt.title('Depth image')\n","#mpld3.display()\n","#plt.show()\n","\n","\n","\n","if True: # draw the trajectory triads\n","    # X_G_traj = plan.GetMyContextFromRoot(context).get_abstract_state(\n","    #     0).get_value()\n","    # # visualize_trajectory(X_G_traj, visualizer)\n","    # i = 0\n","    # for t in np.linspace(X_G_traj.start_time(), X_G_traj.end_time(), 70):\n","    #     i = i + 1\n","    #     AddMeshcatTriad(meshcat,\n","    #                     f\"X_G/({chr(97 + i - 1)})\",\n","    #                     X_PT=X_G_traj.GetPose(t),\n","    #                     length=.1,\n","    #                     radius=0.004)\n","    X_W_S_traj = storage_planner.GetMyContextFromRoot(context).get_abstract_state(\n","        0).get_value()\n","    i = 0\n","    for t in np.linspace(X_W_S_traj.start_time(), X_W_S_traj.end_time(), 70):\n","        i = i + 1\n","        AddMeshcatTriad(meshcat,\n","                        f\"X_G/({chr(97 + i - 1)})\",\n","                        X_PT=X_W_S_traj.GetPose(t),\n","                        length=.1,\n","                        radius=0.004)\n","\n","if running_as_notebook:\n","    visualizer.StartRecording(False)\n","    simulator.AdvanceTo(plan.end_time(plan.GetMyContextFromRoot(context)))\n","    visualizer.PublishRecording()\n","else:\n","    simulator.AdvanceTo(0.1)\n","\n","saat(\"before calling icp\")\n","# icp_pick_and_place_demo()\n","saat(\"after calling icp\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["icp.inputs[9][1]"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"012944c7c22a4b538b7247ea20436ae4","deepnote_cell_type":"code","deepnote_to_be_reexecuted":true,"execution_millis":72777167,"execution_start":1682450271804,"source_hash":"976792d8"},"outputs":[],"source":["\n","with open(\"dg.svg\", \"wb\") as output_file:\n","    output_file.write(\n","        pydot.graph_from_dot_data(\n","            diagram.GetGraphvizString(max_depth=2))[0].create_svg())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.imshow(np.squeeze(icp.inputs[8].data))\n","plt.title('Depth image')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(icp.inputs[9])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["diff_ik2.GetOutputPort(\"\").Eval(diff_ik2.GetMyContextFromRoot(context))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["diff_ik2.GetOutputPort(\"joint_positions\").Eval(diff_ik2.GetMyContextFromRoot(context))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["diff_ik2.GetInputPort(\"X_WE_desired\").Eval(diff_ik2.GetMyContextFromRoot(context))"]},{"cell_type":"code","execution_count":null,"metadata":{"cell_id":"40923a34f2cd46af87b667d19823ff6e","deepnote_cell_type":"code","deepnote_to_be_reexecuted":false,"execution_millis":1501,"execution_start":1682523047452,"source_hash":"5e50ad31"},"outputs":[],"source":["# SVG(\n","#     pydot.graph_from_dot_data(\n","#         diagram.GetGraphvizString(max_depth=1))[0].create_png())\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt \n","plt.imshow(np.squeeze(icp.inputs[5].data))\n","plt.title('Depth image')\n","\n","res = icp.inputs[5].data\n","\n","#and masks[i]['area'] > 30000\n","masks = mask_generator.generate(res[:,:,:3])\n","for i in range(len(masks)):\n","    if (masks[i]['stability_score'] > 0.99  ):\n","        image = np.array(masks[i][\"segmentation\"])\n","        plt.figure(figsize=(20,20))\n","        plt.imshow(image)\n","        plt.axis('off')\n","        plt.show()\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"},"source":["<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=29fb9f43-5ddf-4394-96be-7b378ea2c223' target=\"_blank\">\n","<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n","Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Robotic Manipulation - Geometric Pose Estimation.ipynb","provenance":[],"toc_visible":true},"deepnote":{},"deepnote_execution_queue":[],"deepnote_notebook_id":"e2966185bd644560bfce07f30ec97610","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"vscode":{"interpreter":{"hash":"767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"}}},"nbformat":4,"nbformat_minor":0}
